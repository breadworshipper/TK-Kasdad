{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kombinasi 2 Preprocessing :\n",
    "* Delete Duplicate\n",
    "* Impute Null pake iterative imputer\n",
    "* Outlier capping di sisi kanan\n",
    "* Encoding \n",
    "* Standard scaler\n",
    "* Feature selection -> K-Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Punya Andi/UFC_kombinasi2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>B_avg_opp_SIG_STR_att</th>\n",
       "      <th>B_avg_TOTAL_STR_att</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_att</th>\n",
       "      <th>B_avg_opp_HEAD_att</th>\n",
       "      <th>B_avg_opp_BODY_att</th>\n",
       "      <th>B_avg_opp_BODY_landed</th>\n",
       "      <th>B_avg_opp_DISTANCE_att</th>\n",
       "      <th>B_win_by_KO/TKO</th>\n",
       "      <th>B_Height_cms</th>\n",
       "      <th>...</th>\n",
       "      <th>R_avg_opp_TOTAL_STR_att</th>\n",
       "      <th>R_avg_BODY_att</th>\n",
       "      <th>R_avg_opp_BODY_att</th>\n",
       "      <th>R_avg_DISTANCE_att</th>\n",
       "      <th>R_win_by_KO/TKO</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>gender</th>\n",
       "      <th>B_Reach_cms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>131.687500</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.937500</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.88</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.88</td>\n",
       "      <td>177.80</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>89.953125</td>\n",
       "      <td>141.210938</td>\n",
       "      <td>91.882812</td>\n",
       "      <td>83.210938</td>\n",
       "      <td>3.960938</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>88.695312</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177.80</td>\n",
       "      <td>...</td>\n",
       "      <td>129.593750</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>17.593750</td>\n",
       "      <td>98.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.34</td>\n",
       "      <td>187.96</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>74.937500</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>97.914062</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.218750</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.88</td>\n",
       "      <td>...</td>\n",
       "      <td>113.221941</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.42</td>\n",
       "      <td>185.42</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>37.226562</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>52.046875</td>\n",
       "      <td>28.773438</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>4.453125</td>\n",
       "      <td>24.234375</td>\n",
       "      <td>3.0</td>\n",
       "      <td>175.26</td>\n",
       "      <td>...</td>\n",
       "      <td>125.441042</td>\n",
       "      <td>8.181122</td>\n",
       "      <td>8.554874</td>\n",
       "      <td>67.441225</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177.80</td>\n",
       "      <td>185.42</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>93.299805</td>\n",
       "      <td>102.170410</td>\n",
       "      <td>125.859863</td>\n",
       "      <td>76.181396</td>\n",
       "      <td>10.418213</td>\n",
       "      <td>9.236328</td>\n",
       "      <td>69.770264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.10</td>\n",
       "      <td>...</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>19.159180</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.02</td>\n",
       "      <td>167.64</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_class  B_avg_opp_SIG_STR_att  B_avg_TOTAL_STR_att  \\\n",
       "0           7.0              82.500000            37.000000   \n",
       "1           5.0              89.953125           141.210938   \n",
       "2           6.0              74.937500            66.000000   \n",
       "3           6.0              37.226562            51.500000   \n",
       "4           3.0              93.299805           102.170410   \n",
       "\n",
       "   B_avg_opp_TOTAL_STR_att  B_avg_opp_HEAD_att  B_avg_opp_BODY_att  \\\n",
       "0               131.687500           65.000000           11.000000   \n",
       "1                91.882812           83.210938            3.960938   \n",
       "2                97.914062           59.750000            8.000000   \n",
       "3                52.046875           28.773438            6.656250   \n",
       "4               125.859863           76.181396           10.418213   \n",
       "\n",
       "   B_avg_opp_BODY_landed  B_avg_opp_DISTANCE_att  B_win_by_KO/TKO  \\\n",
       "0               6.937500               71.000000              0.0   \n",
       "1               2.070312               88.695312              3.0   \n",
       "2               5.218750               64.500000              0.0   \n",
       "3               4.453125               24.234375              3.0   \n",
       "4               9.236328               69.770264              0.0   \n",
       "\n",
       "   B_Height_cms  ...  R_avg_opp_TOTAL_STR_att  R_avg_BODY_att  \\\n",
       "0        182.88  ...                97.000000        8.250000   \n",
       "1        177.80  ...               129.593750       20.125000   \n",
       "2        182.88  ...               113.221941       12.500000   \n",
       "3        175.26  ...               125.441042        8.181122   \n",
       "4        165.10  ...               165.000000       20.125000   \n",
       "\n",
       "   R_avg_opp_BODY_att  R_avg_DISTANCE_att  R_win_by_KO/TKO  R_Height_cms  \\\n",
       "0            5.000000           40.000000              0.0        182.88   \n",
       "1           17.593750           98.250000              0.0        180.34   \n",
       "2            2.968750           76.750000              0.0        185.42   \n",
       "3            8.554874           67.441225              4.0        177.80   \n",
       "4           19.159180           88.000000              3.0        160.02   \n",
       "\n",
       "   R_Reach_cms  R_Weight_lbs  gender  B_Reach_cms  \n",
       "0       177.80         185.0     1.0       190.50  \n",
       "1       187.96         170.0     1.0       177.80  \n",
       "2       185.42         170.0     1.0       190.50  \n",
       "3       185.42         170.0     1.0       175.26  \n",
       "4       167.64         135.0     1.0       170.18  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['B_Reach_cms'], axis=1)\n",
    "y = df['B_Reach_cms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'leaf_size': 10, 'metric': 'manhattan', 'n_neighbors': 15, 'p': 1, 'weights': 'distance'}\n",
      "Best R-squared Score: 0.7292596941270275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create the KNN model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit the data to perform grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best R-squared Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared: 0.7292596941270275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate the best model using 5-fold cross-validation\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Calculate the mean R-squared\n",
    "mean_r2 = cv_scores.mean()\n",
    "print(\"Mean R-squared:\", mean_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 4.881872371825598\n"
     ]
    }
   ],
   "source": [
    "# Calculate the RMSE using 5-fold cross-validation\n",
    "cv_rmse = np.sqrt(np.abs(cross_val_score(grid_search.best_estimator_, X, y, cv=5, scoring='neg_mean_squared_error')))\n",
    "\n",
    "# Calculate the mean RMSE\n",
    "mean_rmse = cv_rmse.mean()\n",
    "print(\"Mean RMSE:\", mean_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Tugas Raihan\\Kuliah\\Matkul\\Semester 5\\Kasdad\\TK-Kasdad\\regression\\knn\\kombinasi1_knn.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Tugas%20Raihan/Kuliah/Matkul/Semester%205/Kasdad/TK-Kasdad/regression/knn/kombinasi1_knn.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mB_Reach_cms\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Tugas%20Raihan/Kuliah/Matkul/Semester%205/Kasdad/TK-Kasdad/regression/knn/kombinasi1_knn.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(df_test)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Tugas%20Raihan/Kuliah/Matkul/Semester%205/Kasdad/TK-Kasdad/regression/knn/kombinasi1_knn.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m kaggle_pred \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(df_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Tugas%20Raihan/Kuliah/Matkul/Semester%205/Kasdad/TK-Kasdad/regression/knn/kombinasi1_knn.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m kaggle_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(kaggle_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Tugas%20Raihan/Kuliah/Matkul/Semester%205/Kasdad/TK-Kasdad/regression/knn/kombinasi1_knn.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m kaggle_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_test_id, kaggle_pred], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_regression.py:240\u001b[0m, in \u001b[0;36mKNeighborsRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    238\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[0;32m    242\u001b[0m weights \u001b[39m=\u001b[39m _get_weights(neigh_dist, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[0;32m    244\u001b[0m _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:804\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    802\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    803\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 804\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    806\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    807\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[0;32m    958\u001b[0m             array,\n\u001b[0;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    123\u001b[0m     X,\n\u001b[0;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    129\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../Kaggle_Test_Data.csv')\n",
    "df_test_id = df_test['id']\n",
    "df_test = df_test.drop(['id'], axis=1)\n",
    "df_test = df_test.reindex(columns=df.columns, fill_value=0)\n",
    "df_test = df_test.drop(['B_Reach_cms'], axis=1)\n",
    "df_test = scaler.transform(df_test)\n",
    "kaggle_pred = grid_search.best_estimator_.predict(df_test)\n",
    "kaggle_pred = pd.DataFrame(kaggle_pred)\n",
    "kaggle_pred = pd.concat([df_test_id, kaggle_pred], axis=1)\n",
    "pd.DataFrame(kaggle_pred).to_csv('./kaggle/kombinasi1_knn', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
