{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kombinasi 9 :\n",
    "* Delete Duplicate\n",
    "* Delete Null\n",
    "* Outlier capping winsorize sisi kanan\n",
    "* Encoding \n",
    "* Standard scaler\n",
    "* Feature selection -> K-Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Without Feature Selection/UFC_kombinasi9_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['B_Reach_cms'], axis=1)\n",
    "y = df['B_Reach_cms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../../regression_kaggle/UFC_kombinasi9_all_features.csv')\n",
    "df_test = df_test.drop(['B_Reach_cms'], axis=1, errors='ignore')\n",
    "df_test_id = df_test['id']\n",
    "df_test = df_test.drop(['id'], axis=1, errors='ignore')\n",
    "# Get the common columns between df and df_test\n",
    "common_columns = list(set(X.columns) & set(df_test.columns))\n",
    "# Update df_test to only include the common columns\n",
    "df_test = df_test[common_columns]\n",
    "X = X[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 33321.6680 - r_squared: -416.6909 - val_loss: 32983.5508 - val_r_squared: -407.5216\n",
      "Epoch 2/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 32389.0234 - r_squared: -402.7643 - val_loss: 31636.3555 - val_r_squared: -390.5747\n",
      "Epoch 3/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 30234.2676 - r_squared: -385.4903 - val_loss: 29018.2188 - val_r_squared: -358.1138\n",
      "Epoch 4/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 26669.9863 - r_squared: -327.0475 - val_loss: 24607.8359 - val_r_squared: -303.2839\n",
      "Epoch 5/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 21990.4980 - r_squared: -279.1728 - val_loss: 19611.3945 - val_r_squared: -241.2243\n",
      "Epoch 6/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 16846.3906 - r_squared: -215.2191 - val_loss: 14459.9033 - val_r_squared: -177.4470\n",
      "Epoch 7/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11842.0020 - r_squared: -152.2188 - val_loss: 9796.3281 - val_r_squared: -120.0112\n",
      "Epoch 8/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7682.2363 - r_squared: -94.3617 - val_loss: 5997.3604 - val_r_squared: -73.1521\n",
      "Epoch 9/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 4514.1099 - r_squared: -55.9474 - val_loss: 3350.1660 - val_r_squared: -40.4184\n",
      "Epoch 10/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 2428.3501 - r_squared: -29.1075 - val_loss: 1678.0328 - val_r_squared: -19.7428\n",
      "Epoch 11/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 1234.4426 - r_squared: -14.8066 - val_loss: 771.0330 - val_r_squared: -8.5127\n",
      "Epoch 12/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 621.4133 - r_squared: -6.9224 - val_loss: 340.6093 - val_r_squared: -3.2052\n",
      "Epoch 13/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 354.2749 - r_squared: -3.4519 - val_loss: 153.1395 - val_r_squared: -0.9004\n",
      "Epoch 14/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 264.2997 - r_squared: -2.4419 - val_loss: 78.6196 - val_r_squared: 0.0176\n",
      "Epoch 15/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 234.3006 - r_squared: -1.9533 - val_loss: 52.8863 - val_r_squared: 0.3405\n",
      "Epoch 16/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 223.2828 - r_squared: -1.8205 - val_loss: 47.9138 - val_r_squared: 0.4095\n",
      "Epoch 17/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 209.8684 - r_squared: -1.6891 - val_loss: 42.8536 - val_r_squared: 0.4604\n",
      "Epoch 18/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 201.6602 - r_squared: -1.5344 - val_loss: 40.5478 - val_r_squared: 0.4951\n",
      "Epoch 19/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 207.0410 - r_squared: -1.5876 - val_loss: 35.8878 - val_r_squared: 0.5540\n",
      "Epoch 20/300\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 201.8036 - r_squared: -1.4865 - val_loss: 35.1113 - val_r_squared: 0.5638\n",
      "Epoch 21/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 207.2130 - r_squared: -1.5567 - val_loss: 34.2816 - val_r_squared: 0.5741\n",
      "Epoch 22/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 199.7425 - r_squared: -1.5205 - val_loss: 32.6188 - val_r_squared: 0.6037\n",
      "Epoch 23/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 198.4570 - r_squared: -1.5177 - val_loss: 33.0751 - val_r_squared: 0.5928\n",
      "Epoch 24/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 194.8654 - r_squared: -1.4372 - val_loss: 32.9456 - val_r_squared: 0.5944\n",
      "Epoch 25/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 190.3355 - r_squared: -1.3616 - val_loss: 32.1766 - val_r_squared: 0.6014\n",
      "Epoch 26/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 195.5312 - r_squared: -1.4702 - val_loss: 30.6881 - val_r_squared: 0.6187\n",
      "Epoch 27/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 186.0093 - r_squared: -1.3240 - val_loss: 33.6266 - val_r_squared: 0.5811\n",
      "Epoch 28/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 189.6551 - r_squared: -1.3665 - val_loss: 29.8821 - val_r_squared: 0.6324\n",
      "Epoch 29/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 178.7301 - r_squared: -1.2239 - val_loss: 28.4532 - val_r_squared: 0.6481\n",
      "Epoch 30/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 180.9520 - r_squared: -1.2758 - val_loss: 28.7550 - val_r_squared: 0.6394\n",
      "Epoch 31/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 180.2344 - r_squared: -1.3093 - val_loss: 26.8952 - val_r_squared: 0.6729\n",
      "Epoch 32/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 177.7907 - r_squared: -1.2253 - val_loss: 27.5174 - val_r_squared: 0.6636\n",
      "Epoch 33/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 176.9782 - r_squared: -1.2436 - val_loss: 27.4045 - val_r_squared: 0.6611\n",
      "Epoch 34/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 172.0897 - r_squared: -1.1141 - val_loss: 29.6688 - val_r_squared: 0.6266\n",
      "Epoch 35/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 169.3161 - r_squared: -1.1628 - val_loss: 26.7935 - val_r_squared: 0.6731\n",
      "Epoch 36/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 170.8539 - r_squared: -1.1644 - val_loss: 28.0866 - val_r_squared: 0.6444\n",
      "Epoch 37/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 169.7695 - r_squared: -1.1299 - val_loss: 28.8554 - val_r_squared: 0.6417\n",
      "Epoch 38/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 161.9065 - r_squared: -1.0438 - val_loss: 29.6980 - val_r_squared: 0.6364\n",
      "Epoch 39/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 163.4005 - r_squared: -1.0502 - val_loss: 25.4661 - val_r_squared: 0.6868\n",
      "Epoch 40/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 164.0050 - r_squared: -1.0875 - val_loss: 22.8695 - val_r_squared: 0.7180\n",
      "Epoch 41/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 174.1660 - r_squared: -1.2169 - val_loss: 23.8675 - val_r_squared: 0.7025\n",
      "Epoch 42/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 158.8583 - r_squared: -0.9673 - val_loss: 25.5511 - val_r_squared: 0.6863\n",
      "Epoch 43/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 156.1902 - r_squared: -0.9744 - val_loss: 27.7498 - val_r_squared: 0.6597\n",
      "Epoch 44/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 160.1052 - r_squared: -0.9973 - val_loss: 25.4532 - val_r_squared: 0.6853\n",
      "Epoch 45/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 156.7794 - r_squared: -0.9418 - val_loss: 23.9431 - val_r_squared: 0.7052\n",
      "Epoch 46/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 158.2783 - r_squared: -0.9663 - val_loss: 22.0224 - val_r_squared: 0.7321\n",
      "Epoch 47/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 147.9849 - r_squared: -0.8546 - val_loss: 21.9600 - val_r_squared: 0.7317\n",
      "Epoch 48/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 156.2124 - r_squared: -0.9663 - val_loss: 21.0610 - val_r_squared: 0.7410\n",
      "Epoch 49/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 155.2797 - r_squared: -0.9948 - val_loss: 23.4521 - val_r_squared: 0.7159\n",
      "Epoch 50/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 152.3211 - r_squared: -0.9479 - val_loss: 21.8030 - val_r_squared: 0.7314\n",
      "Epoch 51/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 149.3659 - r_squared: -0.8779 - val_loss: 22.4600 - val_r_squared: 0.7197\n",
      "Epoch 52/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 155.0738 - r_squared: -0.9781 - val_loss: 23.1891 - val_r_squared: 0.7182\n",
      "Epoch 53/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 147.6451 - r_squared: -0.8731 - val_loss: 22.8646 - val_r_squared: 0.7166\n",
      "Epoch 54/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 144.9687 - r_squared: -0.8356 - val_loss: 23.6839 - val_r_squared: 0.7047\n",
      "Epoch 55/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 142.3725 - r_squared: -0.7642 - val_loss: 25.0071 - val_r_squared: 0.6982\n",
      "Epoch 56/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 152.4536 - r_squared: -0.9400 - val_loss: 22.4977 - val_r_squared: 0.7192\n",
      "Epoch 57/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 148.9743 - r_squared: -0.8540 - val_loss: 21.8321 - val_r_squared: 0.7300\n",
      "Epoch 58/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 140.5217 - r_squared: -0.7733 - val_loss: 20.9040 - val_r_squared: 0.7434\n",
      "Epoch 59/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 145.8172 - r_squared: -0.8513 - val_loss: 22.9038 - val_r_squared: 0.7150\n",
      "Epoch 60/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 142.3291 - r_squared: -0.7825 - val_loss: 24.0216 - val_r_squared: 0.6990\n",
      "Epoch 61/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 151.2395 - r_squared: -0.8978 - val_loss: 22.5766 - val_r_squared: 0.7240\n",
      "Epoch 62/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 145.5659 - r_squared: -0.7958 - val_loss: 23.2563 - val_r_squared: 0.7176\n",
      "Epoch 63/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 141.1071 - r_squared: -0.7891 - val_loss: 21.9880 - val_r_squared: 0.7293\n",
      "Epoch 64/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 136.9518 - r_squared: -0.7203 - val_loss: 21.7578 - val_r_squared: 0.7321\n",
      "Epoch 65/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 148.3044 - r_squared: -0.8713 - val_loss: 23.3295 - val_r_squared: 0.7134\n",
      "Epoch 66/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 140.4742 - r_squared: -0.7570 - val_loss: 24.1211 - val_r_squared: 0.6987\n",
      "Epoch 67/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 138.0665 - r_squared: -0.7472 - val_loss: 22.1577 - val_r_squared: 0.7190\n",
      "Epoch 68/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 140.3293 - r_squared: -0.7560 - val_loss: 21.9909 - val_r_squared: 0.7281\n",
      "Epoch 69/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 132.3589 - r_squared: -0.6820 - val_loss: 22.4788 - val_r_squared: 0.7249\n",
      "Epoch 70/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 143.7772 - r_squared: -0.7961 - val_loss: 21.0284 - val_r_squared: 0.7357\n",
      "Epoch 71/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 135.1482 - r_squared: -0.6877 - val_loss: 22.7596 - val_r_squared: 0.7193\n",
      "Epoch 72/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 134.7926 - r_squared: -0.7123 - val_loss: 22.2784 - val_r_squared: 0.7283\n",
      "Epoch 73/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 132.7514 - r_squared: -0.6955 - val_loss: 20.8046 - val_r_squared: 0.7403\n",
      "Epoch 74/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 138.3140 - r_squared: -0.7664 - val_loss: 19.4539 - val_r_squared: 0.7569\n",
      "Epoch 75/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 137.8791 - r_squared: -0.7251 - val_loss: 22.5019 - val_r_squared: 0.7215\n",
      "Epoch 76/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 134.4250 - r_squared: -0.6833 - val_loss: 20.1495 - val_r_squared: 0.7480\n",
      "Epoch 77/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 137.8223 - r_squared: -0.7592 - val_loss: 21.6583 - val_r_squared: 0.7336\n",
      "Epoch 78/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 131.3666 - r_squared: -0.6361 - val_loss: 19.4800 - val_r_squared: 0.7629\n",
      "Epoch 79/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 127.0566 - r_squared: -0.6575 - val_loss: 21.0282 - val_r_squared: 0.7386\n",
      "Epoch 80/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 130.0107 - r_squared: -0.6171 - val_loss: 20.7786 - val_r_squared: 0.7463\n",
      "Epoch 81/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 129.1601 - r_squared: -0.6104 - val_loss: 19.8742 - val_r_squared: 0.7516\n",
      "Epoch 82/300\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 132.1840 - r_squared: -0.6557 - val_loss: 21.2192 - val_r_squared: 0.7382\n",
      "Epoch 83/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 129.5979 - r_squared: -0.6117 - val_loss: 20.1677 - val_r_squared: 0.7481\n",
      "Epoch 84/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 135.0777 - r_squared: -0.7168 - val_loss: 20.4357 - val_r_squared: 0.7462\n",
      "Epoch 85/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 128.0434 - r_squared: -0.5926 - val_loss: 24.8095 - val_r_squared: 0.6950\n",
      "Epoch 86/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 131.6523 - r_squared: -0.6616 - val_loss: 21.2506 - val_r_squared: 0.7382\n",
      "Epoch 87/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 139.4595 - r_squared: -0.7246 - val_loss: 20.0352 - val_r_squared: 0.7533\n",
      "Epoch 88/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 135.1645 - r_squared: -0.7213 - val_loss: 19.4369 - val_r_squared: 0.7620\n",
      "Epoch 89/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 127.8782 - r_squared: -0.6268 - val_loss: 20.0097 - val_r_squared: 0.7580\n",
      "Epoch 90/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 129.0898 - r_squared: -0.6223 - val_loss: 19.4698 - val_r_squared: 0.7574\n",
      "Epoch 91/300\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 126.4194 - r_squared: -0.5745 - val_loss: 20.4201 - val_r_squared: 0.7431\n",
      "Epoch 92/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 131.0019 - r_squared: -0.6327 - val_loss: 19.8543 - val_r_squared: 0.7551\n",
      "Epoch 93/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 118.8832 - r_squared: -0.5270 - val_loss: 22.4174 - val_r_squared: 0.7232\n",
      "Epoch 94/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 125.8452 - r_squared: -0.5909 - val_loss: 20.4074 - val_r_squared: 0.7492\n",
      "Epoch 95/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 127.7104 - r_squared: -0.6134 - val_loss: 21.3016 - val_r_squared: 0.7378\n",
      "Epoch 96/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 127.9468 - r_squared: -0.5774 - val_loss: 20.5975 - val_r_squared: 0.7441\n",
      "Epoch 97/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 120.1139 - r_squared: -0.4850 - val_loss: 21.3170 - val_r_squared: 0.7353\n",
      "Epoch 98/300\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 124.9233 - r_squared: -0.5683 - val_loss: 21.5606 - val_r_squared: 0.7327\n",
      "Epoch 99/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 129.9183 - r_squared: -0.6648 - val_loss: 19.9435 - val_r_squared: 0.7515\n",
      "Epoch 100/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 125.5737 - r_squared: -0.5817 - val_loss: 20.9205 - val_r_squared: 0.7399\n",
      "Epoch 101/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 122.7221 - r_squared: -0.5660 - val_loss: 18.7354 - val_r_squared: 0.7651\n",
      "Epoch 102/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 123.1958 - r_squared: -0.5613 - val_loss: 21.5609 - val_r_squared: 0.7315\n",
      "Epoch 103/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 128.5663 - r_squared: -0.5929 - val_loss: 19.0223 - val_r_squared: 0.7646\n",
      "Epoch 104/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 127.7798 - r_squared: -0.5916 - val_loss: 18.8710 - val_r_squared: 0.7675\n",
      "Epoch 105/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 124.7740 - r_squared: -0.5543 - val_loss: 20.2564 - val_r_squared: 0.7485\n",
      "Epoch 106/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 122.5798 - r_squared: -0.5511 - val_loss: 19.9438 - val_r_squared: 0.7575\n",
      "Epoch 107/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 127.2981 - r_squared: -0.6239 - val_loss: 19.7987 - val_r_squared: 0.7555\n",
      "Epoch 108/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 124.7510 - r_squared: -0.5706 - val_loss: 20.2299 - val_r_squared: 0.7465\n",
      "Epoch 109/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 129.7540 - r_squared: -0.6510 - val_loss: 19.6544 - val_r_squared: 0.7591\n",
      "Epoch 110/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 121.4691 - r_squared: -0.5140 - val_loss: 21.7430 - val_r_squared: 0.7283\n",
      "Epoch 111/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 123.0558 - r_squared: -0.5318 - val_loss: 19.6388 - val_r_squared: 0.7541\n",
      "Epoch 112/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 124.6040 - r_squared: -0.5938 - val_loss: 19.6753 - val_r_squared: 0.7557\n",
      "Epoch 113/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 128.2543 - r_squared: -0.6219 - val_loss: 21.0389 - val_r_squared: 0.7405\n",
      "Epoch 114/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 123.5175 - r_squared: -0.5631 - val_loss: 19.5014 - val_r_squared: 0.7577\n",
      "Epoch 115/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 120.8256 - r_squared: -0.5174 - val_loss: 19.0547 - val_r_squared: 0.7599\n",
      "Epoch 116/300\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 123.1656 - r_squared: -0.5781 - val_loss: 20.2179 - val_r_squared: 0.7496\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 10.3809 - r_squared: 0.8699\n",
      "R-squared: 0.8699373006820679\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "# Define R-squared metric\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[r_squared])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=300, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, r2_score = model.evaluate(X, y)\n",
    "print(\"R-squared:\", r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "df_test_scaled = scaler.transform(df_test)\n",
    "y_pred = model.predict(df_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(y_pred, columns=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['id'] = df_test_id\n",
    "submission = predictions_df[['id', 'Predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>166.537231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>171.057495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>186.661423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>169.930710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>174.697845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   Predicted\n",
       "0  0.0  166.537231\n",
       "1  1.0  171.057495\n",
       "2  2.0  186.661423\n",
       "3  3.0  169.930710\n",
       "4  4.0  174.697845"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('pred_kombinasi3_neural_network.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
