{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>B_avg_SIG_STR_att</th>\n",
       "      <th>B_avg_SIG_STR_landed</th>\n",
       "      <th>B_avg_opp_SIG_STR_att</th>\n",
       "      <th>B_avg_opp_SIG_STR_landed</th>\n",
       "      <th>B_avg_TOTAL_STR_att</th>\n",
       "      <th>B_avg_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_TD_att</th>\n",
       "      <th>B_avg_opp_TD_att</th>\n",
       "      <th>...</th>\n",
       "      <th>R_avg_CTRL_time(seconds)</th>\n",
       "      <th>R_avg_opp_CTRL_time(seconds)</th>\n",
       "      <th>R_total_title_bouts</th>\n",
       "      <th>R_win_by_Decision_Unanimous</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>B_age</th>\n",
       "      <th>R_age</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>66.304047</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>27.270996</td>\n",
       "      <td>89.625000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.038061</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125000</td>\n",
       "      <td>89.531250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.88</td>\n",
       "      <td>177.80</td>\n",
       "      <td>185.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>133.937500</td>\n",
       "      <td>53.234375</td>\n",
       "      <td>89.953125</td>\n",
       "      <td>31.296875</td>\n",
       "      <td>141.210938</td>\n",
       "      <td>56.718750</td>\n",
       "      <td>33.078125</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.835938</td>\n",
       "      <td>...</td>\n",
       "      <td>252.312500</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>180.34</td>\n",
       "      <td>187.96</td>\n",
       "      <td>170.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>66.304047</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>27.270996</td>\n",
       "      <td>89.625000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.038061</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125000</td>\n",
       "      <td>89.531250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.42</td>\n",
       "      <td>182.88</td>\n",
       "      <td>170.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>39.218750</td>\n",
       "      <td>19.015625</td>\n",
       "      <td>37.226562</td>\n",
       "      <td>14.531250</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>30.742188</td>\n",
       "      <td>28.671875</td>\n",
       "      <td>2.578125</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>145.693754</td>\n",
       "      <td>116.292816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177.80</td>\n",
       "      <td>185.42</td>\n",
       "      <td>170.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>74.522461</td>\n",
       "      <td>29.986572</td>\n",
       "      <td>93.299805</td>\n",
       "      <td>42.413086</td>\n",
       "      <td>102.170410</td>\n",
       "      <td>51.280762</td>\n",
       "      <td>71.359619</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.682373</td>\n",
       "      <td>...</td>\n",
       "      <td>110.148438</td>\n",
       "      <td>162.796875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.02</td>\n",
       "      <td>167.64</td>\n",
       "      <td>135.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_class  B_avg_SIG_STR_att  B_avg_SIG_STR_landed  \\\n",
       "0             7          66.304047             29.500000   \n",
       "1             5         133.937500             53.234375   \n",
       "2             6          66.304047             29.500000   \n",
       "3             6          39.218750             19.015625   \n",
       "4             3          74.522461             29.986572   \n",
       "\n",
       "   B_avg_opp_SIG_STR_att  B_avg_opp_SIG_STR_landed  B_avg_TOTAL_STR_att  \\\n",
       "0              64.000000                 27.270996            89.625000   \n",
       "1              89.953125                 31.296875           141.210938   \n",
       "2              64.000000                 27.270996            89.625000   \n",
       "3              37.226562                 14.531250            51.500000   \n",
       "4              93.299805                 42.413086           102.170410   \n",
       "\n",
       "   B_avg_TOTAL_STR_landed  B_avg_opp_TOTAL_STR_landed  B_avg_TD_att  \\\n",
       "0               48.000000                   44.500000      2.000000   \n",
       "1               56.718750                   33.078125      2.000000   \n",
       "2               48.000000                   44.500000      2.000000   \n",
       "3               30.742188                   28.671875      2.578125   \n",
       "4               51.280762                   71.359619      5.937500   \n",
       "\n",
       "   B_avg_opp_TD_att  ...  R_avg_CTRL_time(seconds)  \\\n",
       "0          2.038061  ...                104.125000   \n",
       "1          1.835938  ...                252.312500   \n",
       "2          2.038061  ...                104.125000   \n",
       "3          1.625000  ...                145.693754   \n",
       "4          3.682373  ...                110.148438   \n",
       "\n",
       "   R_avg_opp_CTRL_time(seconds)  R_total_title_bouts  \\\n",
       "0                     89.531250                  0.0   \n",
       "1                    115.000000                  0.0   \n",
       "2                     89.531250                  0.0   \n",
       "3                    116.292816                  1.0   \n",
       "4                    162.796875                  1.0   \n",
       "\n",
       "   R_win_by_Decision_Unanimous  R_Height_cms  R_Reach_cms  R_Weight_lbs  \\\n",
       "0                          0.0        182.88       177.80         185.0   \n",
       "1                          4.0        180.34       187.96         170.0   \n",
       "2                          0.0        185.42       182.88         170.0   \n",
       "3                          4.0        177.80       185.42         170.0   \n",
       "4                          2.0        160.02       167.64         135.0   \n",
       "\n",
       "   B_age  R_age  Winner  \n",
       "0   26.0   21.0     Red  \n",
       "1   27.0   30.0    Blue  \n",
       "2   28.0   31.0    Blue  \n",
       "3   28.0   34.0    Blue  \n",
       "4   34.0   31.0     Red  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataframe/UFC_kombinasi7_FS_lasso.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.        ,  66.30404663,  29.5       , ..., 185.        ,\n",
       "         26.        ,  21.        ],\n",
       "       [  5.        , 133.9375    ,  53.234375  , ..., 170.        ,\n",
       "         27.        ,  30.        ],\n",
       "       [  6.        ,  66.30404663,  29.5       , ..., 170.        ,\n",
       "         28.        ,  31.        ],\n",
       "       ...,\n",
       "       [  4.        ,  44.75      ,  16.75      , ..., 145.        ,\n",
       "         24.        ,  30.        ],\n",
       "       [  5.        ,  75.3125    ,  38.421875  , ..., 155.        ,\n",
       "         27.        ,  34.        ],\n",
       "       [  8.        ,  40.25      ,  14.5       , ..., 225.        ,\n",
       "         32.        ,  31.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Winner', axis=1).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Red', 'Blue', 'Blue', ..., 'Red', 'Blue', 'Red'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Winner'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Red': 3581, 'Blue': 1730, 'Draw': 99})\n"
     ]
    }
   ],
   "source": [
    "counter_y = Counter(y)\n",
    "print(counter_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling\n",
    "adasyn = ADASYN()\n",
    "randomOver = RandomOverSampler()\n",
    "smote = SMOTE()\n",
    "borderSmote = BorderlineSMOTE()\n",
    "svmSmote = SVMSMOTE()\n",
    "\n",
    "# Melakukan resampling\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X, y)\n",
    "X_randomOver, y_randomOver = randomOver.fit_resample(X, y)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "X_borderSmote, y_borderSmote = borderSmote.fit_resample(X, y)\n",
    "X_svmSmote, y_svmSmote = svmSmote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# Under Sampling\n",
    "rand_under = RandomUnderSampler(sampling_strategy='majority')\n",
    "nearmiss = NearMiss()\n",
    "nearmiss2 = NearMiss(version=2)\n",
    "nearmiss3 = NearMiss(version=3)\n",
    "tomek = TomekLinks()\n",
    "\n",
    "# Melakukan resampling\n",
    "X_rand_under, y_rand_under = rand_under.fit_resample(X, y)\n",
    "X_nearmiss, y_nearmiss = nearmiss.fit_resample(X, y)\n",
    "X_nearmiss2, y_nearmiss2 = nearmiss2.fit_resample(X, y)\n",
    "X_nearmiss3, y_nearmiss3 = nearmiss3.fit_resample(X, y)\n",
    "X_tomek, y_tomek = tomek.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(classifier):\n",
    "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "  scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "  print(\"ADASYN OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_adasyn, y_adasyn, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Random OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_randomOver, y_randomOver, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"SMOTE OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_smote, y_smote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Borderline SMOTE OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_borderSmote, y_borderSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"SVM SMOTE OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_svmSmote, y_svmSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Random Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_rand_under, y_rand_under , scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Near Miss 1 Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_nearmiss, y_nearmiss, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Near Miss 2 Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_nearmiss2, y_nearmiss2, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Near Miss 3 Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_nearmiss3, y_nearmiss3, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Tomek Links Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_tomek, y_tomek, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7298127263365842\n",
      "f1_macro score: 0.7258091123630892\n",
      "precision_micro score: 0.7262860872880973\n",
      "precision_macro score: 0.7214814902382742\n",
      "recall_micro score: 0.7285134223922686\n",
      "recall_macro score: 0.729033112729264\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.833474146305111\n",
      "f1_macro score: 0.834135809574024\n",
      "precision_micro score: 0.8341257854114295\n",
      "precision_macro score: 0.8376984626994162\n",
      "recall_micro score: 0.834870664368599\n",
      "recall_macro score: 0.8322639333660581\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.7246586043658088\n",
      "f1_macro score: 0.7245613035724524\n",
      "precision_micro score: 0.7255893564457246\n",
      "precision_macro score: 0.722831291799117\n",
      "recall_micro score: 0.7261487522237619\n",
      "recall_macro score: 0.7278253066652123\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.7570509171040534\n",
      "f1_macro score: 0.7570221541015818\n",
      "precision_micro score: 0.760495938953894\n",
      "precision_macro score: 0.7583512124260074\n",
      "recall_micro score: 0.7598445164829166\n",
      "recall_macro score: 0.7603113012266609\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.7248596755877627\n",
      "f1_macro score: 0.7560074519744859\n",
      "precision_micro score: 0.7212415552732627\n",
      "precision_macro score: 0.7512568636224612\n",
      "recall_micro score: 0.7189384425133046\n",
      "recall_macro score: 0.7612837636906965\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.7997900545050804\n",
      "f1_macro score: 0.36015986661913196\n",
      "precision_micro score: 0.8065231141915079\n",
      "precision_macro score: 0.3786765150404819\n",
      "recall_micro score: 0.8060036336720275\n",
      "recall_macro score: 0.37102727918061046\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.717457627118644\n",
      "f1_macro score: 0.7362460202641887\n",
      "precision_micro score: 0.7509604519774011\n",
      "precision_macro score: 0.7319249317352471\n",
      "recall_micro score: 0.7105649717514124\n",
      "recall_macro score: 0.7617543859649122\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.6496610169491526\n",
      "f1_macro score: 0.6231150408882744\n",
      "precision_micro score: 0.6262146892655367\n",
      "precision_macro score: 0.6263191194770142\n",
      "recall_micro score: 0.6328248587570622\n",
      "recall_macro score: 0.6198245614035087\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.4205649717514124\n",
      "f1_macro score: 0.3892568893794618\n",
      "precision_micro score: 0.4274011299435029\n",
      "precision_macro score: 0.39456972030427406\n",
      "recall_micro score: 0.4036723163841808\n",
      "recall_macro score: 0.4101754385964912\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.5934918082747459\n",
      "f1_macro score: 0.3665071592890797\n",
      "precision_micro score: 0.595553663944849\n",
      "precision_macro score: 0.36283563171478794\n",
      "recall_micro score: 0.5999114621099866\n",
      "recall_macro score: 0.36075845686689373\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Random Oversampling menghasilkan score terbaik maka akan digunakan Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8349636875841087\n",
      "f1_macro score: 0.8309974749302811\n",
      "precision_micro score: 0.8330085103027434\n",
      "precision_macro score: 0.8417263142584265\n",
      "recall_micro score: 0.8342181153938475\n",
      "recall_macro score: 0.8379407784868154\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(dt, X_randomOver, y_randomOver, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_randomOver, y_randomOver, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 50],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 50],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 10, 20, 50],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_c = {'criterion': ['gini', 'entropy'],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'max_depth' : [None, 10, 20, 50],\n",
    "               'min_samples_leaf': [1, 2, 4]\n",
    "               }\n",
    "\n",
    "clf_dtc = GridSearchCV(estimator= DecisionTreeClassifier(), param_grid=param_grid_c, cv= 5)\n",
    "clf_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(clf_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_dtc = DecisionTreeClassifier(**clf_dtc.best_params_)\n",
    "best_hypeparam_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8140758402607385\n",
      "f1_macro score: 0.8104824940674824\n",
      "precision_micro score: 0.8150687041478175\n",
      "precision_macro score: 0.8121099229247083\n",
      "recall_micro score: 0.8103510604051241\n",
      "recall_macro score: 0.8138917055303512\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_dtc, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(prediction, y_test):\n",
    "  accuracy = accuracy_score(y_test, prediction)\n",
    "  f1 = f1_score(y_test, prediction, average=\"macro\")\n",
    "  recall = recall_score(y_test, prediction, average=\"macro\")\n",
    "  precision = precision_score(y_test, prediction, average=\"macro\")\n",
    "\n",
    "  print('Accuracy: ' + str(accuracy))\n",
    "  print('F1 Score: ' + str(f1))\n",
    "  print('Recall Score: ' + str(recall))\n",
    "  print('Precision Score: ' + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8224125093075205\n",
      "F1 Score: 0.8204250899326139\n",
      "Recall Score: 0.8240846930655706\n",
      "Precision Score: 0.8259674692288138\n"
     ]
    }
   ],
   "source": [
    "prediction = best_hypeparam_dtc.predict(X_test)\n",
    "classification_metrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8324646314221892\n",
      "F1 Score: 0.8309387236299332\n",
      "Recall Score: 0.8340179164718332\n",
      "Precision Score: 0.836254146368419\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)\n",
    "prediction = dt.predict(X_test)\n",
    "classification_metrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8434187084084648\n",
      "f1_macro score: 0.8441352498068749\n",
      "precision_micro score: 0.8397068422855444\n",
      "precision_macro score: 0.8433414604700097\n",
      "recall_micro score: 0.8462962986899676\n",
      "recall_macro score: 0.8448651281177033\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.8800140033084549\n",
      "f1_macro score: 0.8828594304372503\n",
      "precision_micro score: 0.8768500874773506\n",
      "precision_macro score: 0.883912998761738\n",
      "recall_micro score: 0.8840169478160125\n",
      "recall_macro score: 0.8813150438018955\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.8438982923069325\n",
      "f1_macro score: 0.8419453411801208\n",
      "precision_micro score: 0.8435265460614396\n",
      "precision_macro score: 0.8431291815773714\n",
      "recall_micro score: 0.844270688458449\n",
      "recall_macro score: 0.8437112529186115\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.8438975990738407\n",
      "f1_macro score: 0.8438616654035747\n",
      "precision_micro score: 0.8425943641882716\n",
      "precision_macro score: 0.8452169586096276\n",
      "recall_micro score: 0.8438046625124673\n",
      "recall_macro score: 0.8451988032070311\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.8083116200402266\n",
      "f1_macro score: 0.8349469542158511\n",
      "precision_micro score: 0.8118218355130832\n",
      "precision_macro score: 0.8444948957563844\n",
      "recall_micro score: 0.813795579871236\n",
      "recall_macro score: 0.8351698671723818\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8983406231074624\n",
      "f1_macro score: 0.34640067011307035\n",
      "precision_micro score: 0.8973030078729561\n",
      "precision_macro score: 0.49984560261322664\n",
      "recall_micro score: 0.8978211425879821\n",
      "recall_macro score: 0.34940472568705006\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7914689265536724\n",
      "f1_macro score: 0.7717490568064861\n",
      "precision_micro score: 0.7746327683615819\n",
      "precision_macro score: 0.7995161835967051\n",
      "recall_micro score: 0.7644632768361582\n",
      "recall_macro score: 0.7649122807017543\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.6328248587570622\n",
      "f1_macro score: 0.6439081997054353\n",
      "precision_micro score: 0.6398870056497176\n",
      "precision_macro score: 0.6591379319759092\n",
      "recall_micro score: 0.6230508474576272\n",
      "recall_macro score: 0.6066666666666667\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3942372881355932\n",
      "f1_macro score: 0.41690294897512975\n",
      "precision_micro score: 0.41762711864406776\n",
      "precision_macro score: 0.40492663556727815\n",
      "recall_micro score: 0.4110734463276836\n",
      "recall_macro score: 0.4329824561403509\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.6993594795968767\n",
      "f1_macro score: 0.34307542529294366\n",
      "precision_micro score: 0.6986708807549629\n",
      "precision_macro score: 0.4046383159137199\n",
      "recall_micro score: 0.7050868564582743\n",
      "recall_macro score: 0.3602051058401331\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena score nya paling tinggi maka akan digunakan Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.882156050235136\n",
      "f1_macro score: 0.8823977621632315\n",
      "precision_micro score: 0.8829934758100645\n",
      "precision_macro score: 0.8799728776681175\n",
      "recall_micro score: 0.8802939394963488\n",
      "recall_macro score: 0.8807585922099376\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(rf, X_randomOver, y_randomOver, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_c = {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'max_depth' : [None, 10, 20, 30],\n",
    "               'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "clf_rfc = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid_c, cv=cv)\n",
    "clf_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(clf_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_rfc = RandomForestClassifier(**clf_rfc.best_params_)\n",
    "best_hypeparam_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8540403830365986\n",
      "f1_macro score: 0.8500024401797353\n",
      "precision_micro score: 0.8527989951219361\n",
      "precision_macro score: 0.855224479544572\n",
      "recall_micro score: 0.8490760636012034\n",
      "recall_macro score: 0.8505440757207289\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_rfc, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8659717051377513\n",
      "F1 Score: 0.8668668545479159\n",
      "Recall Score: 0.8669775797996703\n",
      "Precision Score: 0.8671818799948757\n"
     ]
    }
   ],
   "source": [
    "prediction_rf = best_hypeparam_rfc.predict(X_test)\n",
    "classification_metrics(prediction_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(max_iter=2000)\n",
    "logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.5136419589518879\n",
      "f1_macro score: 0.5115914898535976\n",
      "precision_micro score: 0.5136419589518879\n",
      "precision_macro score: 0.5127663993200582\n",
      "recall_micro score: 0.5136419589518879\n",
      "recall_macro score: 0.5133729167425353\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.4858047959598375\n",
      "f1_macro score: 0.48460548022276645\n",
      "precision_micro score: 0.4858047959598375\n",
      "precision_macro score: 0.48540420100027\n",
      "recall_micro score: 0.4858047959598375\n",
      "recall_macro score: 0.48580353687644307\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.5120558433917123\n",
      "f1_macro score: 0.5107872699238839\n",
      "precision_micro score: 0.5120558433917123\n",
      "precision_macro score: 0.5114053573431475\n",
      "recall_micro score: 0.5120558433917123\n",
      "recall_macro score: 0.5120516896129902\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.6529832852836147\n",
      "f1_macro score: 0.6439265760553193\n",
      "precision_micro score: 0.6529832852836147\n",
      "precision_macro score: 0.6452321188873411\n",
      "recall_micro score: 0.6529832852836147\n",
      "recall_macro score: 0.6529795158286779\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.6047802326029006\n",
      "f1_macro score: 0.6102351297848406\n",
      "precision_micro score: 0.6047802326029006\n",
      "precision_macro score: 0.6071569905534665\n",
      "recall_micro score: 0.6047802326029006\n",
      "recall_macro score: 0.6144698810399272\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8931498553260212\n",
      "f1_macro score: 0.326817096912805\n",
      "precision_micro score: 0.8931498553260211\n",
      "precision_macro score: 0.3884350408200998\n",
      "recall_micro score: 0.8931498553260211\n",
      "recall_macro score: 0.3380732177263969\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7106214689265536\n",
      "f1_macro score: 0.715894068868365\n",
      "precision_micro score: 0.7106214689265536\n",
      "precision_macro score: 0.7407151860738226\n",
      "recall_micro score: 0.7106214689265536\n",
      "recall_macro score: 0.7114035087719298\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.4578531073446328\n",
      "f1_macro score: 0.45522186621031296\n",
      "precision_micro score: 0.4578531073446328\n",
      "precision_macro score: 0.46048505977453347\n",
      "recall_micro score: 0.4578531073446328\n",
      "recall_macro score: 0.45771929824561397\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.36700564971751415\n",
      "f1_macro score: 0.3647500224447414\n",
      "precision_micro score: 0.36700564971751415\n",
      "precision_macro score: 0.36500099741720415\n",
      "recall_micro score: 0.36700564971751415\n",
      "recall_macro score: 0.3664912280701754\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.7011901384028499\n",
      "f1_macro score: 0.36802374432501345\n",
      "precision_micro score: 0.7011901384028499\n",
      "precision_macro score: 0.4069272190907447\n",
      "recall_micro score: 0.7011901384028499\n",
      "recall_macro score: 0.37574140990664084\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Nearmiss 1 undersampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7106214689265536\n",
      "f1_macro score: 0.715894068868365\n",
      "precision_micro score: 0.7106214689265536\n",
      "precision_macro score: 0.7407151860738226\n",
      "recall_micro score: 0.7106214689265536\n",
      "recall_macro score: 0.7114035087719298\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(logistic, X_nearmiss, y_nearmiss, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_nearmiss, y_nearmiss, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.max_iter = 10000\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.6795959595959596\n",
      "f1_macro score: 0.6845910561321404\n",
      "precision_micro score: 0.6795959595959596\n",
      "precision_macro score: 0.7197487479840421\n",
      "recall_micro score: 0.6795959595959596\n",
      "recall_macro score: 0.6776190476190476\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(logistic, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "F1 Score: 0.7327897666243531\n",
      "Recall Score: 0.7269668737060041\n",
      "Precision Score: 0.7402298850574712\n"
     ]
    }
   ],
   "source": [
    "prediction_logreg = logistic.predict(X_test)\n",
    "classification_metrics(prediction_logreg, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000, multi_class='multinomial')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = LogisticRegression(max_iter=2000, multi_class='multinomial')\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.5136419589518879\n",
      "f1_macro score: 0.5115914898535976\n",
      "precision_micro score: 0.5136419589518879\n",
      "precision_macro score: 0.5127663993200582\n",
      "recall_micro score: 0.5136419589518879\n",
      "recall_macro score: 0.5133729167425353\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.4858047959598375\n",
      "f1_macro score: 0.48460548022276645\n",
      "precision_micro score: 0.4858047959598375\n",
      "precision_macro score: 0.48540420100027\n",
      "recall_micro score: 0.4858047959598375\n",
      "recall_macro score: 0.48580353687644307\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.5120558433917123\n",
      "f1_macro score: 0.5107872699238839\n",
      "precision_micro score: 0.5120558433917123\n",
      "precision_macro score: 0.5114053573431475\n",
      "recall_micro score: 0.5120558433917123\n",
      "recall_macro score: 0.5120516896129902\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.6529832852836147\n",
      "f1_macro score: 0.6439265760553193\n",
      "precision_micro score: 0.6529832852836147\n",
      "precision_macro score: 0.6452321188873411\n",
      "recall_micro score: 0.6529832852836147\n",
      "recall_macro score: 0.6529795158286779\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.6047802326029006\n",
      "f1_macro score: 0.6102351297848406\n",
      "precision_micro score: 0.6047802326029006\n",
      "precision_macro score: 0.6071569905534665\n",
      "recall_micro score: 0.6047802326029006\n",
      "recall_macro score: 0.6144698810399272\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8931498553260212\n",
      "f1_macro score: 0.326817096912805\n",
      "precision_micro score: 0.8931498553260211\n",
      "precision_macro score: 0.3884350408200998\n",
      "recall_micro score: 0.8931498553260211\n",
      "recall_macro score: 0.3380732177263969\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7106214689265536\n",
      "f1_macro score: 0.715894068868365\n",
      "precision_micro score: 0.7106214689265536\n",
      "precision_macro score: 0.7407151860738226\n",
      "recall_micro score: 0.7106214689265536\n",
      "recall_macro score: 0.7114035087719298\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.4578531073446328\n",
      "f1_macro score: 0.45522186621031296\n",
      "precision_micro score: 0.4578531073446328\n",
      "precision_macro score: 0.46048505977453347\n",
      "recall_micro score: 0.4578531073446328\n",
      "recall_macro score: 0.45771929824561397\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.36700564971751415\n",
      "f1_macro score: 0.3647500224447414\n",
      "precision_micro score: 0.36700564971751415\n",
      "precision_macro score: 0.36500099741720415\n",
      "recall_micro score: 0.36700564971751415\n",
      "recall_macro score: 0.3664912280701754\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.7011901384028499\n",
      "f1_macro score: 0.36802374432501345\n",
      "precision_micro score: 0.7011901384028499\n",
      "precision_macro score: 0.4069272190907447\n",
      "recall_micro score: 0.7011901384028499\n",
      "recall_macro score: 0.37574140990664084\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Nearmiss 1 undersampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7106214689265536\n",
      "f1_macro score: 0.715894068868365\n",
      "precision_micro score: 0.7106214689265536\n",
      "precision_macro score: 0.7407151860738226\n",
      "recall_micro score: 0.7106214689265536\n",
      "recall_macro score: 0.7114035087719298\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(softmax, X_nearmiss, y_nearmiss, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, multi_class='multinomial')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax.max_iter = 10000\n",
    "softmax.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "F1 Score: 0.7327897666243531\n",
      "Recall Score: 0.7269668737060041\n",
      "Precision Score: 0.7402298850574712\n"
     ]
    }
   ],
   "source": [
    "prediction_softmax = softmax.predict(X_test)\n",
    "classification_metrics(prediction_softmax, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n",
      "f1_micro score: 0.7215510990182835\n",
      "f1_macro score: 0.7013045689062141\n",
      "precision_micro score: 0.7215510990182835\n",
      "precision_macro score: 0.7215729304860842\n",
      "recall_micro score: 0.7215510990182835\n",
      "recall_macro score: 0.7206720226032364\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.7281033229261716\n",
      "f1_macro score: 0.7215774165272746\n",
      "precision_micro score: 0.7281033229261716\n",
      "precision_macro score: 0.7194711871483047\n",
      "recall_micro score: 0.7281033229261716\n",
      "recall_macro score: 0.728102688368928\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.7293128846902072\n",
      "f1_macro score: 0.7116162458185753\n",
      "precision_micro score: 0.7293128846902072\n",
      "precision_macro score: 0.7278910789258819\n",
      "recall_micro score: 0.7293128846902072\n",
      "recall_macro score: 0.7293136361157212\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.7592845574529923\n",
      "f1_macro score: 0.7517289736510588\n",
      "precision_micro score: 0.7592845574529923\n",
      "precision_macro score: 0.7660439516711102\n",
      "recall_micro score: 0.7592845574529923\n",
      "recall_macro score: 0.7592841058725447\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.7208026580439031\n",
      "f1_macro score: 0.7495523764023243\n",
      "precision_micro score: 0.7208026580439029\n",
      "precision_macro score: 0.752181052144923\n",
      "recall_micro score: 0.7208026580439029\n",
      "recall_macro score: 0.7579131688652423\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8947123342978266\n",
      "f1_macro score: 0.3209464508094645\n",
      "precision_micro score: 0.8947123342978266\n",
      "precision_macro score: 0.3326388888888889\n",
      "recall_micro score: 0.8947123342978266\n",
      "recall_macro score: 0.33551059730250476\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7208474576271187\n",
      "f1_macro score: 0.7242945952379632\n",
      "precision_micro score: 0.7208474576271187\n",
      "precision_macro score: 0.7443577970216817\n",
      "recall_micro score: 0.7208474576271187\n",
      "recall_macro score: 0.7210526315789474\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.5922598870056497\n",
      "f1_macro score: 0.597379484795586\n",
      "precision_micro score: 0.5922598870056497\n",
      "precision_macro score: 0.6125173262650112\n",
      "recall_micro score: 0.5922598870056497\n",
      "recall_macro score: 0.5926315789473684\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.34367231638418083\n",
      "f1_macro score: 0.32588873880456176\n",
      "precision_micro score: 0.34367231638418083\n",
      "precision_macro score: 0.3286395872780761\n",
      "recall_micro score: 0.34367231638418083\n",
      "recall_macro score: 0.3429824561403509\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.677361360698635\n",
      "f1_macro score: 0.382696500489172\n",
      "precision_micro score: 0.677361360698635\n",
      "precision_macro score: 0.45334453202220715\n",
      "recall_micro score: 0.677361360698635\n",
      "recall_macro score: 0.38234701164704604\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Borderline SMOTE oversampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7592845574529923\n",
      "f1_macro score: 0.7517289736510588\n",
      "precision_micro score: 0.7592845574529923\n",
      "precision_macro score: 0.7660439516711102\n",
      "recall_micro score: 0.7592845574529923\n",
      "recall_macro score: 0.7592841058725447\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(knn, X_borderSmote, y_borderSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_borderSmote, y_borderSmote, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.75449846 0.76442849 0.74233549 0.74270686 0.72905452 0.72768906\n",
      " 0.71614752 0.71130657 0.70795662        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.49695718 0.50105278 0.50750647 0.52376489 0.52041301 0.52364105\n",
      " 0.52029094 0.51818038 0.50688451]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;jaccard&#x27;],\n",
       "                          &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10]}],\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;jaccard&#x27;],\n",
       "                          &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10]}],\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'metric': ['euclidean', 'manhattan', 'jaccard'],\n",
       "                          'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]}],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = [{'n_neighbors': [2,3,4,5,6,7,8,9,10],'metric': ['euclidean', 'manhattan', 'jaccard']}]\n",
    "\n",
    "clf_knn = GridSearchCV(knn, tuned_params, cv=cv, verbose = 2)\n",
    "clf_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(clf_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_knn = KNeighborsClassifier(**clf_knn.best_params_)\n",
    "best_hypeparam_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7644284871533025\n",
      "f1_macro score: 0.7569397646451896\n",
      "precision_micro score: 0.7644284871533025\n",
      "precision_macro score: 0.7712758547986633\n",
      "recall_micro score: 0.7644284871533025\n",
      "recall_macro score: 0.7636980152622866\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_knn, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7710349962769918\n",
      "F1 Score: 0.7668805293102157\n",
      "Recall Score: 0.7732183784290091\n",
      "Precision Score: 0.7809957435053269\n"
     ]
    }
   ],
   "source": [
    "prediction_knn = best_hypeparam_knn.predict(X_test)\n",
    "classification_metrics(prediction_knn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n",
      "f1_micro score: 0.5897453397014566\n",
      "f1_macro score: 0.6172886363071676\n",
      "precision_micro score: 0.6672573768761296\n",
      "precision_macro score: 0.6518853136503827\n",
      "recall_micro score: 0.6167585046543742\n",
      "recall_macro score: 0.6247418122208181\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.6738342635654884\n",
      "f1_macro score: 0.5918308099482146\n",
      "precision_micro score: 0.6396774559731997\n",
      "precision_macro score: 0.6727305217317031\n",
      "recall_micro score: 0.6896573088864684\n",
      "recall_macro score: 0.6545770578320076\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.6428429315787604\n",
      "f1_macro score: 0.6342972138202732\n",
      "precision_micro score: 0.6487904815630327\n",
      "precision_macro score: 0.670594261018308\n",
      "recall_micro score: 0.6623856923622178\n",
      "recall_macro score: 0.6482364964716945\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.6949615818885921\n",
      "f1_macro score: 0.7147301251174826\n",
      "precision_micro score: 0.6469163692263432\n",
      "precision_macro score: 0.6815758369968576\n",
      "recall_micro score: 0.6810915908226337\n",
      "recall_macro score: 0.7029736721130097\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.6556647635957693\n",
      "f1_macro score: 0.6932567458269328\n",
      "precision_micro score: 0.6697018963343631\n",
      "precision_macro score: 0.7116541897722212\n",
      "recall_micro score: 0.6568586338308744\n",
      "recall_macro score: 0.7005273781584315\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8231868649485229\n",
      "f1_macro score: 0.3420327168831879\n",
      "precision_micro score: 0.8438355426956463\n",
      "precision_macro score: 0.338305863958288\n",
      "recall_micro score: 0.8464437117286858\n",
      "recall_macro score: 0.36146841091167226\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.6699435028248588\n",
      "f1_macro score: 0.6662673329784619\n",
      "precision_micro score: 0.6598305084745764\n",
      "precision_macro score: 0.7021412568626191\n",
      "recall_micro score: 0.6769491525423729\n",
      "recall_macro score: 0.6836842105263158\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.5794350282485876\n",
      "f1_macro score: 0.5700126446945097\n",
      "precision_micro score: 0.5221468926553672\n",
      "precision_macro score: 0.5630131310324379\n",
      "recall_micro score: 0.585819209039548\n",
      "recall_macro score: 0.5643859649122807\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.36333333333333334\n",
      "f1_macro score: 0.3360755843376824\n",
      "precision_micro score: 0.43107344632768363\n",
      "precision_macro score: 0.34910012180318206\n",
      "recall_micro score: 0.33293785310734464\n",
      "recall_macro score: 0.4091228070175439\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.6594682997572433\n",
      "f1_macro score: 0.3341100999101971\n",
      "precision_micro score: 0.651475456351083\n",
      "precision_macro score: 0.38970112689749475\n",
      "recall_micro score: 0.6418227245499543\n",
      "recall_macro score: 0.3892718252061598\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Borderline SMOTE Oversampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.6880788171363754\n",
      "f1_macro score: 0.7086390164301617\n",
      "precision_micro score: 0.7104166504190161\n",
      "precision_macro score: 0.7143606746965666\n",
      "recall_micro score: 0.7256840260898274\n",
      "recall_macro score: 0.6977322487397053\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(mlp, X_borderSmote, y_borderSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_borderSmote, y_borderSmote, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (30, 20, 10)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [10000],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "tuned_mlp = GridSearchCV(mlp, param_grid, cv=cv)\n",
    "tuned_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'activation': 'logistic', 'alpha': 1e-05, 'hidden_layer_sizes': 10, 'max_iter': 1000, 'random_state': 42, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(tuned_mlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=1e-05, hidden_layer_sizes=10,\n",
       "              max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=1e-05, hidden_layer_sizes=10,\n",
       "              max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=10,\n",
       "              max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_mlp = MLPClassifier(**tuned_mlp.best_params_)\n",
    "best_hypeparam_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.676993063883709\n",
      "f1_macro score: 0.7118221371248534\n",
      "precision_micro score: 0.676993063883709\n",
      "precision_macro score: 0.7119523723308918\n",
      "recall_micro score: 0.676993063883709\n",
      "recall_macro score: 0.7161506430083246\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_mlp, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6658428077113199\n",
      "F1 Score: 0.7016426666936328\n",
      "Recall Score: 0.7031492494782547\n",
      "Precision Score: 0.7056713141602785\n"
     ]
    }
   ],
   "source": [
    "prediction_mlp = best_hypeparam_mlp.predict(X_test)\n",
    "classification_metrics(prediction_mlp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari semua model classification, untuk kobinasi pre processing ini yang menghasilkan hasil paling bagus adalah Random Forest dengan data yang di Random Oversampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
