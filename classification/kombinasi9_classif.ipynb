{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>B_avg_KD</th>\n",
       "      <th>B_avg_opp_KD</th>\n",
       "      <th>B_avg_SIG_STR_pct</th>\n",
       "      <th>B_avg_opp_SIG_STR_pct</th>\n",
       "      <th>B_avg_TD_pct</th>\n",
       "      <th>B_avg_opp_TD_pct</th>\n",
       "      <th>B_avg_SUB_ATT</th>\n",
       "      <th>B_avg_opp_SUB_ATT</th>\n",
       "      <th>B_avg_REV</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394141</td>\n",
       "      <td>0.352422</td>\n",
       "      <td>0.239219</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600839</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.088281</td>\n",
       "      <td>0.104375</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.266602</td>\n",
       "      <td>0.381462</td>\n",
       "      <td>0.456558</td>\n",
       "      <td>0.429614</td>\n",
       "      <td>0.469570</td>\n",
       "      <td>1.351562</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_class  B_avg_KD  B_avg_opp_KD  B_avg_SIG_STR_pct  \\\n",
       "0             5  0.785156      0.000000           0.394141   \n",
       "1             6  0.695312      0.000000           0.600839   \n",
       "2             3  0.500000      0.266602           0.381462   \n",
       "3             5  0.000000      0.000000           0.470000   \n",
       "4             6  0.500000      0.000000           0.460000   \n",
       "\n",
       "   B_avg_opp_SIG_STR_pct  B_avg_TD_pct  B_avg_opp_TD_pct  B_avg_SUB_ATT  \\\n",
       "0               0.352422      0.239219          0.011484       0.156250   \n",
       "1               0.185547      0.088281          0.104375       0.093750   \n",
       "2               0.456558      0.429614          0.469570       1.351562   \n",
       "3               0.250000      0.750000          0.000000       0.000000   \n",
       "4               0.292500      0.125000          0.100000       0.000000   \n",
       "\n",
       "   B_avg_opp_SUB_ATT  B_avg_REV  ...  gender  B_Stance_Open Stance  \\\n",
       "0           0.132812      0.000  ...       1                 False   \n",
       "1           0.062500      0.000  ...       1                 False   \n",
       "2           0.000244      0.125  ...       1                 False   \n",
       "3           0.000000      0.000  ...       1                 False   \n",
       "4           0.000000      0.000  ...       1                 False   \n",
       "\n",
       "   B_Stance_Orthodox  B_Stance_Southpaw  B_Stance_Switch  \\\n",
       "0               True              False            False   \n",
       "1              False               True            False   \n",
       "2               True              False            False   \n",
       "3               True              False            False   \n",
       "4               True              False            False   \n",
       "\n",
       "   R_Stance_Open Stance  R_Stance_Orthodox  R_Stance_Southpaw  \\\n",
       "0                 False               True              False   \n",
       "1                 False               True              False   \n",
       "2                 False               True              False   \n",
       "3                 False               True              False   \n",
       "4                 False               True              False   \n",
       "\n",
       "   R_Stance_Switch  Winner  \n",
       "0            False    Blue  \n",
       "1            False    Blue  \n",
       "2            False     Red  \n",
       "3            False     Red  \n",
       "4            False    Blue  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataframe/UFC_kombinasi9_all_features.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {'Blue': 0, 'Draw': 1, 'Red': 2}\n",
    "df_xgb = df.copy()\n",
    "\n",
    "df_xgb[\"Winner\"]= df_xgb['Winner'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0.78515625, 0.0, ..., True, False, False],\n",
       "       [6, 0.6953125, 0.0, ..., True, False, False],\n",
       "       [3, 0.5, 0.2666015625, ..., True, False, False],\n",
       "       ...,\n",
       "       [6, 0.015625, 0.0, ..., False, True, False],\n",
       "       [5, 0.78515625, 0.125, ..., True, False, False],\n",
       "       [8, 0.5, 0.0, ..., True, False, False]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Winner', axis=1).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Winner'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 2141, 0: 1277, 1: 62})\n"
     ]
    }
   ],
   "source": [
    "counter_y = Counter(y)\n",
    "print(counter_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling\n",
    "adasyn = ADASYN()\n",
    "randomOver = RandomOverSampler()\n",
    "smote = SMOTE()\n",
    "borderSmote = BorderlineSMOTE()\n",
    "svmSmote = SVMSMOTE()\n",
    "\n",
    "# Melakukan resampling\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X, y)\n",
    "X_randomOver, y_randomOver = randomOver.fit_resample(X, y)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "X_borderSmote, y_borderSmote = borderSmote.fit_resample(X, y)\n",
    "X_svmSmote, y_svmSmote = svmSmote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# Under Sampling\n",
    "rand_under = RandomUnderSampler(sampling_strategy='majority')\n",
    "nearmiss = NearMiss()\n",
    "nearmiss2 = NearMiss(version=2)\n",
    "nearmiss3 = NearMiss(version=3)\n",
    "tomek = TomekLinks()\n",
    "\n",
    "# Melakukan resampling\n",
    "X_rand_under, y_rand_under = rand_under.fit_resample(X, y)\n",
    "X_nearmiss, y_nearmiss = nearmiss.fit_resample(X, y)\n",
    "X_nearmiss2, y_nearmiss2 = nearmiss2.fit_resample(X, y)\n",
    "X_nearmiss3, y_nearmiss3 = nearmiss3.fit_resample(X, y)\n",
    "X_tomek, y_tomek = tomek.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(classifier):\n",
    "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "  scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "  print(\"ADASYN OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_adasyn, y_adasyn, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Random OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_randomOver, y_randomOver, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"SMOTE OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_smote, y_smote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Borderline SMOTE OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_borderSmote, y_borderSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"SVM SMOTE OverSampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_svmSmote, y_svmSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Random Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_rand_under, y_rand_under , scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Near Miss 1 Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_nearmiss, y_nearmiss, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Near Miss 2 Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_nearmiss2, y_nearmiss2, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Near Miss 3 Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_nearmiss3, y_nearmiss3, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  print(\"Tomek Links Undersampling\")\n",
    "  for i in range(len(scoring)):\n",
    "    score = cross_val_score(classifier, X_tomek, y_tomek, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7212167857765682\n",
      "f1_macro score: 0.7181945930159586\n",
      "precision_micro score: 0.7251200020029112\n",
      "precision_macro score: 0.7204271558579404\n",
      "recall_micro score: 0.7241895548184688\n",
      "recall_macro score: 0.7233793144939494\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.8456676831196877\n",
      "f1_macro score: 0.8368110544621246\n",
      "precision_micro score: 0.8395243381140421\n",
      "precision_macro score: 0.8456674107078271\n",
      "recall_micro score: 0.8425017309163761\n",
      "recall_macro score: 0.839614938095572\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.7112539893398081\n",
      "f1_macro score: 0.711653286193266\n",
      "precision_micro score: 0.7121846114385193\n",
      "precision_macro score: 0.7110172070248624\n",
      "recall_micro score: 0.7117188887820155\n",
      "recall_macro score: 0.7177703497658618\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.7469966109567224\n",
      "f1_macro score: 0.7446836537064249\n",
      "precision_micro score: 0.7469051908427375\n",
      "precision_macro score: 0.7433592309912026\n",
      "recall_micro score: 0.7496973604283488\n",
      "recall_macro score: 0.7499745473717564\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.6947120720977451\n",
      "f1_macro score: 0.7308353477250186\n",
      "precision_micro score: 0.6986503758059346\n",
      "precision_macro score: 0.7209988005037837\n",
      "recall_micro score: 0.7016341680618388\n",
      "recall_macro score: 0.742923521754885\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.7805988829823027\n",
      "f1_macro score: 0.3401093389749722\n",
      "precision_micro score: 0.7707502859834466\n",
      "precision_macro score: 0.34646579671809136\n",
      "recall_micro score: 0.781115671892874\n",
      "recall_macro score: 0.3419541628638069\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7407909604519773\n",
      "f1_macro score: 0.7198375446254193\n",
      "precision_micro score: 0.7576271186440677\n",
      "precision_macro score: 0.7337934168228286\n",
      "recall_micro score: 0.7441807909604521\n",
      "recall_macro score: 0.7236842105263158\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.5824858757062146\n",
      "f1_macro score: 0.5580730144016408\n",
      "precision_micro score: 0.5522598870056498\n",
      "precision_macro score: 0.5827852346125331\n",
      "recall_micro score: 0.5723728813559321\n",
      "recall_macro score: 0.5635087719298245\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3970621468926554\n",
      "f1_macro score: 0.37916843155876656\n",
      "precision_micro score: 0.39361581920903954\n",
      "precision_macro score: 0.39860863852432926\n",
      "recall_micro score: 0.4\n",
      "recall_macro score: 0.40122807017543866\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.5983589738261779\n",
      "f1_macro score: 0.3682747332195898\n",
      "precision_micro score: 0.6081685077778614\n",
      "precision_macro score: 0.37561612939910616\n",
      "recall_micro score: 0.6017828432505722\n",
      "recall_macro score: 0.3700378025010275\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Random Oversampling menghasilkan score terbaik maka akan digunakan Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8417569819404115\n",
      "f1_macro score: 0.8379619715001215\n",
      "precision_micro score: 0.8418509583514224\n",
      "precision_macro score: 0.8482557372772039\n",
      "recall_micro score: 0.8413844991347584\n",
      "recall_macro score: 0.8414766160471029\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(dt, X_randomOver, y_randomOver, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_randomOver, y_randomOver, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 50],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 50],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 10, 20, 50],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_c = {'criterion': ['gini', 'entropy'],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'max_depth' : [None, 10, 20, 50],\n",
    "               'min_samples_leaf': [1, 2, 4]\n",
    "               }\n",
    "\n",
    "clf_dtc = GridSearchCV(estimator= DecisionTreeClassifier(), param_grid=param_grid_c, cv= 5)\n",
    "clf_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(clf_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_dtc = DecisionTreeClassifier(**clf_dtc.best_params_)\n",
    "best_hypeparam_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7986836775086911\n",
      "f1_macro score: 0.7963262772994624\n",
      "precision_micro score: 0.8001731273672164\n",
      "precision_macro score: 0.805788214074504\n",
      "recall_micro score: 0.7999246803535864\n",
      "recall_macro score: 0.7989455667852969\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_dtc, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(prediction, y_test):\n",
    "  accuracy = accuracy_score(y_test, prediction)\n",
    "  f1 = f1_score(y_test, prediction, average=\"macro\")\n",
    "  recall = recall_score(y_test, prediction, average=\"macro\")\n",
    "  precision = precision_score(y_test, prediction, average=\"macro\")\n",
    "\n",
    "  print('Accuracy: ' + str(accuracy))\n",
    "  print('F1 Score: ' + str(f1))\n",
    "  print('Recall Score: ' + str(recall))\n",
    "  print('Precision Score: ' + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8339538346984363\n",
      "F1 Score: 0.8318367609671232\n",
      "Recall Score: 0.8355769940688603\n",
      "Precision Score: 0.8395026347867974\n"
     ]
    }
   ],
   "source": [
    "prediction = best_hypeparam_dtc.predict(X_test)\n",
    "classification_metrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8276247207743858\n",
      "F1 Score: 0.825615369386176\n",
      "Recall Score: 0.8293041780490406\n",
      "Precision Score: 0.8338456107825182\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)\n",
    "prediction = dt.predict(X_test)\n",
    "classification_metrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8452748563860922\n",
      "f1_macro score: 0.8414868804639493\n",
      "precision_micro score: 0.8453671888624328\n",
      "precision_macro score: 0.8398981422589724\n",
      "recall_micro score: 0.8451820059154944\n",
      "recall_macro score: 0.8478579136299829\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.8859728183304695\n",
      "f1_macro score: 0.8834234582832602\n",
      "precision_micro score: 0.8818773272051528\n",
      "precision_macro score: 0.882246129361792\n",
      "recall_micro score: 0.8858791452089362\n",
      "recall_macro score: 0.8842962478150996\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.8458540328401846\n",
      "f1_macro score: 0.8462084404771002\n",
      "precision_micro score: 0.8434334795188615\n",
      "precision_macro score: 0.8454288895480181\n",
      "recall_micro score: 0.8424093576068901\n",
      "recall_macro score: 0.8441782307306722\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.8477144538233106\n",
      "f1_macro score: 0.8474011093872518\n",
      "precision_micro score: 0.8473419276905891\n",
      "precision_macro score: 0.8481578626019493\n",
      "recall_micro score: 0.8459458862248519\n",
      "recall_macro score: 0.8458510917359472\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.7992585046129734\n",
      "f1_macro score: 0.8401622192979126\n",
      "precision_micro score: 0.8004527481922132\n",
      "precision_macro score: 0.8451986780624026\n",
      "recall_micro score: 0.7990211234994479\n",
      "recall_macro score: 0.834316100731616\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.9004171993809299\n",
      "f1_macro score: 0.3603404402088884\n",
      "precision_micro score: 0.9004171993809299\n",
      "precision_macro score: 0.5668427284248618\n",
      "recall_micro score: 0.899899064665904\n",
      "recall_macro score: 0.3536842105263158\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7980790960451978\n",
      "f1_macro score: 0.7967314503313834\n",
      "precision_micro score: 0.8048587570621469\n",
      "precision_macro score: 0.7906646447035464\n",
      "recall_micro score: 0.8014689265536724\n",
      "recall_macro score: 0.7817543859649122\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.6229378531073446\n",
      "f1_macro score: 0.615894202612864\n",
      "precision_micro score: 0.6230508474576272\n",
      "precision_macro score: 0.670719913631252\n",
      "recall_micro score: 0.6467796610169492\n",
      "recall_macro score: 0.6228070175438597\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.39378531073446327\n",
      "f1_macro score: 0.39488624591281035\n",
      "precision_micro score: 0.4103954802259887\n",
      "precision_macro score: 0.40177233298418297\n",
      "recall_micro score: 0.3803389830508475\n",
      "recall_macro score: 0.41368421052631577\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.7000238959176941\n",
      "f1_macro score: 0.337070318611174\n",
      "precision_micro score: 0.7004812949509485\n",
      "precision_macro score: 0.4115295694090255\n",
      "recall_micro score: 0.6977439136837895\n",
      "recall_macro score: 0.3615641135431347\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena score nya paling tinggi maka akan digunakan Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8805742223007886\n",
      "f1_macro score: 0.8805567588370946\n",
      "precision_micro score: 0.879735496913813\n",
      "precision_macro score: 0.8799383279868742\n",
      "recall_micro score: 0.8787114183289096\n",
      "recall_macro score: 0.8789893748263118\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(rf, X_randomOver, y_randomOver, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [20, 30], &#x27;min_samples_leaf&#x27;: [1],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [20, 30], &#x27;min_samples_leaf&#x27;: [1],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [20, 30], 'min_samples_leaf': [1],\n",
       "                         'min_samples_split': [2, 5, 10]})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_c = {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'max_depth' : [None, 10, 20, 30],\n",
    "               'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "clf_rfc = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid_c, cv=cv)\n",
    "clf_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(clf_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=30, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=30, min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=30, min_samples_split=5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_rfc = RandomForestClassifier(**clf_rfc.best_params_)\n",
    "best_hypeparam_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8469667284318574\n",
      "f1_macro score: 0.8457015100170413\n",
      "precision_micro score: 0.843492012882894\n",
      "precision_macro score: 0.8449712407254802\n",
      "recall_micro score: 0.8462221575305013\n",
      "recall_macro score: 0.8465934080586337\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_rfc, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8715562174236783\n",
      "F1 Score: 0.8723924833932717\n",
      "Recall Score: 0.8724895200124694\n",
      "Precision Score: 0.8724791911066422\n"
     ]
    }
   ],
   "source": [
    "prediction_rf = best_hypeparam_rfc.predict(X_test)\n",
    "classification_metrics(prediction_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(max_iter=2000)\n",
    "logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.5859117648582336\n",
      "f1_macro score: 0.5830382177643059\n",
      "precision_micro score: 0.5859117648582336\n",
      "precision_macro score: 0.5833519393944753\n",
      "recall_micro score: 0.5859117648582336\n",
      "recall_macro score: 0.585442866709181\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.5721854519836432\n",
      "f1_macro score: 0.5708080996787424\n",
      "precision_micro score: 0.5721854519836432\n",
      "precision_macro score: 0.5710988152215268\n",
      "recall_micro score: 0.5721854519836432\n",
      "recall_macro score: 0.5721818356539377\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.5925708375902178\n",
      "f1_macro score: 0.5902618807914692\n",
      "precision_micro score: 0.5925708375902178\n",
      "precision_macro score: 0.5901893240335436\n",
      "recall_micro score: 0.5925708375902178\n",
      "recall_macro score: 0.5925643263234718\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.6610812876458064\n",
      "f1_macro score: 0.6536985852376753\n",
      "precision_micro score: 0.6610812876458064\n",
      "precision_macro score: 0.6532892537670374\n",
      "recall_micro score: 0.6610812876458064\n",
      "recall_macro score: 0.6610825418345112\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.617257222242012\n",
      "f1_macro score: 0.6078310344427441\n",
      "precision_micro score: 0.617257222242012\n",
      "precision_macro score: 0.6262050616204634\n",
      "recall_micro score: 0.617257222242012\n",
      "recall_macro score: 0.5953348429996985\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8827885068299576\n",
      "f1_macro score: 0.34919778029906906\n",
      "precision_micro score: 0.8827885068299576\n",
      "precision_macro score: 0.39600901349094575\n",
      "recall_micro score: 0.8827885068299576\n",
      "recall_macro score: 0.3499229287090559\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7203954802259886\n",
      "f1_macro score: 0.7255289175801811\n",
      "precision_micro score: 0.7203954802259886\n",
      "precision_macro score: 0.742341030441717\n",
      "recall_micro score: 0.7203954802259886\n",
      "recall_macro score: 0.7205263157894737\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.47824858757062144\n",
      "f1_macro score: 0.47075216879168646\n",
      "precision_micro score: 0.47824858757062144\n",
      "precision_macro score: 0.47811722232736803\n",
      "recall_micro score: 0.47824858757062144\n",
      "recall_macro score: 0.4784210526315789\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3501129943502825\n",
      "f1_macro score: 0.34792518873584133\n",
      "precision_micro score: 0.3501129943502825\n",
      "precision_macro score: 0.3582800754606931\n",
      "recall_micro score: 0.3501129943502825\n",
      "recall_macro score: 0.34912280701754383\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.7020763474570327\n",
      "f1_macro score: 0.3866593813756516\n",
      "precision_micro score: 0.7020763474570327\n",
      "precision_macro score: 0.41220430750580517\n",
      "recall_micro score: 0.7020763474570327\n",
      "recall_macro score: 0.3893017807396172\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Nearmiss 1 undersampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7203954802259886\n",
      "f1_macro score: 0.7255289175801811\n",
      "precision_micro score: 0.7203954802259886\n",
      "precision_macro score: 0.742341030441717\n",
      "recall_micro score: 0.7203954802259886\n",
      "recall_macro score: 0.7205263157894737\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(logistic, X_nearmiss, y_nearmiss, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_nearmiss, y_nearmiss, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.max_iter = 10000\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.6842424242424242\n",
      "f1_macro score: 0.6885655632886215\n",
      "precision_micro score: 0.6842424242424242\n",
      "precision_macro score: 0.7189281954640684\n",
      "recall_micro score: 0.6842424242424242\n",
      "recall_macro score: 0.6818253968253968\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(logistic, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "F1 Score: 0.7314034802406897\n",
      "Recall Score: 0.727743271221532\n",
      "Precision Score: 0.7408289241622574\n"
     ]
    }
   ],
   "source": [
    "prediction_logreg = logistic.predict(X_test)\n",
    "classification_metrics(prediction_logreg, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000, multi_class='multinomial')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = LogisticRegression(max_iter=2000, multi_class='multinomial')\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.5859117648582336\n",
      "f1_macro score: 0.5830382177643059\n",
      "precision_micro score: 0.5859117648582336\n",
      "precision_macro score: 0.5833519393944753\n",
      "recall_micro score: 0.5859117648582336\n",
      "recall_macro score: 0.585442866709181\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.5721854519836432\n",
      "f1_macro score: 0.5708080996787424\n",
      "precision_micro score: 0.5721854519836432\n",
      "precision_macro score: 0.5710988152215268\n",
      "recall_micro score: 0.5721854519836432\n",
      "recall_macro score: 0.5721818356539377\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.5925708375902178\n",
      "f1_macro score: 0.5902618807914692\n",
      "precision_micro score: 0.5925708375902178\n",
      "precision_macro score: 0.5901893240335436\n",
      "recall_micro score: 0.5925708375902178\n",
      "recall_macro score: 0.5925643263234718\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.6610812876458064\n",
      "f1_macro score: 0.6536985852376753\n",
      "precision_micro score: 0.6610812876458064\n",
      "precision_macro score: 0.6532892537670374\n",
      "recall_micro score: 0.6610812876458064\n",
      "recall_macro score: 0.6610825418345112\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.617257222242012\n",
      "f1_macro score: 0.6078310344427441\n",
      "precision_micro score: 0.617257222242012\n",
      "precision_macro score: 0.6262050616204634\n",
      "recall_micro score: 0.617257222242012\n",
      "recall_macro score: 0.5953348429996985\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8827885068299576\n",
      "f1_macro score: 0.34919778029906906\n",
      "precision_micro score: 0.8827885068299576\n",
      "precision_macro score: 0.39600901349094575\n",
      "recall_micro score: 0.8827885068299576\n",
      "recall_macro score: 0.3499229287090559\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7203954802259886\n",
      "f1_macro score: 0.7255289175801811\n",
      "precision_micro score: 0.7203954802259886\n",
      "precision_macro score: 0.742341030441717\n",
      "recall_micro score: 0.7203954802259886\n",
      "recall_macro score: 0.7205263157894737\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.47824858757062144\n",
      "f1_macro score: 0.47075216879168646\n",
      "precision_micro score: 0.47824858757062144\n",
      "precision_macro score: 0.47811722232736803\n",
      "recall_micro score: 0.47824858757062144\n",
      "recall_macro score: 0.4784210526315789\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3501129943502825\n",
      "f1_macro score: 0.34792518873584133\n",
      "precision_micro score: 0.3501129943502825\n",
      "precision_macro score: 0.3582800754606931\n",
      "recall_micro score: 0.3501129943502825\n",
      "recall_macro score: 0.34912280701754383\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.7020763474570327\n",
      "f1_macro score: 0.3866593813756516\n",
      "precision_micro score: 0.7020763474570327\n",
      "precision_macro score: 0.41220430750580517\n",
      "recall_micro score: 0.7020763474570327\n",
      "recall_macro score: 0.3893017807396172\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Nearmiss 1 undersampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7203954802259886\n",
      "f1_macro score: 0.7255289175801811\n",
      "precision_micro score: 0.7203954802259886\n",
      "precision_macro score: 0.742341030441717\n",
      "recall_micro score: 0.7203954802259886\n",
      "recall_macro score: 0.7205263157894737\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(softmax, X_nearmiss, y_nearmiss, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, multi_class='multinomial')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax.max_iter = 10000\n",
    "softmax.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "F1 Score: 0.7314034802406897\n",
      "Recall Score: 0.727743271221532\n",
      "Precision Score: 0.7408289241622574\n"
     ]
    }
   ],
   "source": [
    "prediction_softmax = softmax.predict(X_test)\n",
    "classification_metrics(prediction_softmax, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7214944306984117\n",
      "f1_macro score: 0.7009685554498203\n",
      "precision_micro score: 0.7214944306984117\n",
      "precision_macro score: 0.721462240166198\n",
      "recall_micro score: 0.7214944306984117\n",
      "recall_macro score: 0.7206894923163788\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.7336882686763493\n",
      "f1_macro score: 0.7273848956687254\n",
      "precision_micro score: 0.7336882686763493\n",
      "precision_macro score: 0.7257128921016075\n",
      "recall_micro score: 0.7336882686763493\n",
      "recall_macro score: 0.7336869430614318\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.7289415717153968\n",
      "f1_macro score: 0.7109074940344692\n",
      "precision_micro score: 0.7289415717153965\n",
      "precision_macro score: 0.7285688265715726\n",
      "recall_micro score: 0.7289415717153965\n",
      "recall_macro score: 0.7289398980336546\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.7522117168524098\n",
      "f1_macro score: 0.7413021420767496\n",
      "precision_micro score: 0.7522117168524098\n",
      "precision_macro score: 0.7558431723784282\n",
      "recall_micro score: 0.7522117168524098\n",
      "recall_macro score: 0.7522133397744066\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.6938778185445089\n",
      "f1_macro score: 0.7250685660243602\n",
      "precision_micro score: 0.6938778185445089\n",
      "precision_macro score: 0.7125887345471498\n",
      "recall_micro score: 0.6938778185445089\n",
      "recall_macro score: 0.7507537829984402\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8967875647668393\n",
      "f1_macro score: 0.3215341210791856\n",
      "precision_micro score: 0.8967875647668393\n",
      "precision_macro score: 0.365888254304705\n",
      "recall_micro score: 0.8967875647668393\n",
      "recall_macro score: 0.33628131021194607\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.7210169491525423\n",
      "f1_macro score: 0.726272773505308\n",
      "precision_micro score: 0.7210169491525423\n",
      "precision_macro score: 0.7452083812591059\n",
      "recall_micro score: 0.7210169491525423\n",
      "recall_macro score: 0.7217543859649123\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.6166101694915255\n",
      "f1_macro score: 0.6244924636101107\n",
      "precision_micro score: 0.6166101694915255\n",
      "precision_macro score: 0.6496468376824414\n",
      "recall_micro score: 0.6166101694915255\n",
      "recall_macro score: 0.6159649122807018\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3705649717514124\n",
      "f1_macro score: 0.3542197726610075\n",
      "precision_micro score: 0.3705649717514124\n",
      "precision_macro score: 0.36239948335790123\n",
      "recall_micro score: 0.3705649717514124\n",
      "recall_macro score: 0.3703508771929825\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.6715272348527155\n",
      "f1_macro score: 0.3744800648416215\n",
      "precision_micro score: 0.6715272348527155\n",
      "precision_macro score: 0.38378218310000034\n",
      "recall_micro score: 0.6715272348527155\n",
      "recall_macro score: 0.3771226290310109\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Borderline SMOTE oversampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7522117168524098\n",
      "f1_macro score: 0.7413021420767496\n",
      "precision_micro score: 0.7522117168524098\n",
      "precision_macro score: 0.7558431723784282\n",
      "recall_micro score: 0.7522117168524098\n",
      "recall_macro score: 0.7522133397744066\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(knn, X_borderSmote, y_borderSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_borderSmote, y_borderSmote, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=2; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=3; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=4; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=5; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=6; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=7; total time=   0.5s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=8; total time=   0.3s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.1s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.2s\n",
      "[CV] END ....................metric=euclidean, n_neighbors=9; total time=   0.2s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.1s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.4s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.2s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.1s\n",
      "[CV] END ...................metric=euclidean, n_neighbors=10; total time=   0.1s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=2; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=7; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=8; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'Blue'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ....................metric=manhattan, n_neighbors=9; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...................metric=manhattan, n_neighbors=10; total time=   0.0s\n",
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=2; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=3; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=4; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=5; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=6; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=7; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=8; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................metric=jaccard, n_neighbors=9; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................metric=jaccard, n_neighbors=10; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.7504024  0.75462222 0.73439174 0.73377208 0.72011913 0.71229982\n",
      " 0.70609381 0.69889577 0.6951723         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70795577 0.73625493 0.72036703 0.73240632 0.72185671 0.72570395\n",
      " 0.71689016 0.72433887 0.71875374]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;jaccard&#x27;],\n",
       "                          &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10]}],\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;jaccard&#x27;],\n",
       "                          &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7, 8, 9, 10]}],\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'metric': ['euclidean', 'manhattan', 'jaccard'],\n",
       "                          'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]}],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = [{'n_neighbors': [2,3,4,5,6,7,8,9,10],'metric': ['euclidean', 'manhattan', 'jaccard']}]\n",
    "\n",
    "clf_knn = GridSearchCV(knn, tuned_params, cv=cv, verbose = 2)\n",
    "clf_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(clf_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_knn = KNeighborsClassifier(**clf_knn.best_params_)\n",
    "best_hypeparam_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7546222234544454\n",
      "f1_macro score: 0.7440798354728558\n",
      "precision_micro score: 0.7546222234544454\n",
      "precision_macro score: 0.758287500775975\n",
      "recall_micro score: 0.7546222234544454\n",
      "recall_macro score: 0.753836383020513\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_knn, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7784810126582279\n",
      "F1 Score: 0.7715069909432618\n",
      "Recall Score: 0.7806938294171223\n",
      "Precision Score: 0.7892214454322285\n"
     ]
    }
   ],
   "source": [
    "prediction_knn = best_hypeparam_knn.predict(X_test)\n",
    "classification_metrics(prediction_knn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.6337643764989458\n",
      "f1_macro score: 0.4986538312531386\n",
      "precision_micro score: 0.5793258132078176\n",
      "precision_macro score: 0.6801726079650029\n",
      "recall_micro score: 0.6006899251843628\n",
      "recall_macro score: 0.6194356673483867\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.6869557362005454\n",
      "f1_macro score: 0.6989007456147197\n",
      "precision_micro score: 0.6838757449006208\n",
      "precision_macro score: 0.7247158189242031\n",
      "recall_micro score: 0.6961755630135882\n",
      "recall_macro score: 0.695979004178906\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.6703882885201466\n",
      "f1_macro score: 0.64915182093164\n",
      "precision_micro score: 0.6315743843440238\n",
      "precision_macro score: 0.6979141470595417\n",
      "recall_micro score: 0.6568099752775749\n",
      "recall_macro score: 0.6756594957782401\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.6984072103173881\n",
      "f1_macro score: 0.5970926245309673\n",
      "precision_micro score: 0.7215860653216211\n",
      "precision_macro score: 0.7231679492526064\n",
      "recall_micro score: 0.6893797556873277\n",
      "recall_macro score: 0.679159751603126\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.6295533074484381\n",
      "f1_macro score: 0.6084256095777765\n",
      "precision_micro score: 0.6410092259466391\n",
      "precision_macro score: 0.7027680022796947\n",
      "recall_micro score: 0.6145125209275817\n",
      "recall_macro score: 0.6846043239477921\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.8392490411143261\n",
      "f1_macro score: 0.3268307454721554\n",
      "precision_micro score: 0.827322522037548\n",
      "precision_macro score: 0.3720671448101446\n",
      "recall_micro score: 0.8293694906130138\n",
      "recall_macro score: 0.35766859344894025\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.5992655367231638\n",
      "f1_macro score: 0.6260759019076156\n",
      "precision_micro score: 0.7003954802259887\n",
      "precision_macro score: 0.6472539842147685\n",
      "recall_micro score: 0.6770621468926553\n",
      "recall_macro score: 0.6980701754385965\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.5927118644067797\n",
      "f1_macro score: 0.5845300196451091\n",
      "precision_micro score: 0.6266101694915254\n",
      "precision_macro score: 0.5388181464761318\n",
      "recall_micro score: 0.5790395480225989\n",
      "recall_macro score: 0.5905263157894737\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3331638418079096\n",
      "f1_macro score: 0.327315807665278\n",
      "precision_micro score: 0.35689265536723164\n",
      "precision_macro score: 0.3343295794332946\n",
      "recall_micro score: 0.32666666666666666\n",
      "recall_macro score: 0.32\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.632064944948481\n",
      "f1_macro score: 0.3429414482871786\n",
      "precision_micro score: 0.6448866632208061\n",
      "precision_macro score: 0.43426484690237965\n",
      "recall_micro score: 0.6751736999451954\n",
      "recall_macro score: 0.41264192394288185\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena Borderline SMOTE Oversampling menghasilkan nilai terbaik maka akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.7025959846206239\n",
      "f1_macro score: 0.6691094688466002\n",
      "precision_micro score: 0.7052933112538594\n",
      "precision_macro score: 0.7259910963800189\n",
      "recall_micro score: 0.6956187668596454\n",
      "recall_macro score: 0.6829646598048459\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(mlp, X_borderSmote, y_borderSmote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_borderSmote, y_borderSmote, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (30, 20, 10)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [10000],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "tuned_mlp = GridSearchCV(mlp, param_grid, cv=cv)\n",
    "tuned_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'activation': 'logistic', 'alpha': 1e-05, 'hidden_layer_sizes': 10, 'max_iter': 1000, 'random_state': 42, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(tuned_mlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=1e-05, hidden_layer_sizes=10,\n",
       "              max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=1e-05, hidden_layer_sizes=10,\n",
       "              max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=10,\n",
       "              max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hypeparam_mlp = MLPClassifier(**tuned_mlp.best_params_)\n",
    "best_hypeparam_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.676993063883709\n",
      "f1_macro score: 0.7118221371248534\n",
      "precision_micro score: 0.676993063883709\n",
      "precision_macro score: 0.7119523723308918\n",
      "recall_micro score: 0.676993063883709\n",
      "recall_macro score: 0.7161506430083246\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_hypeparam_mlp, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6658428077113199\n",
      "F1 Score: 0.7016426666936328\n",
      "Recall Score: 0.7031492494782547\n",
      "Precision Score: 0.7056713141602785\n"
     ]
    }
   ],
   "source": [
    "prediction_mlp = best_hypeparam_mlp.predict(X_test)\n",
    "classification_metrics(prediction_mlp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari semua model classification, untuk kobinasi pre processing ini yang menghasilkan hasil paling bagus adalah Random Forest dengan data yang di Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN OverSampling\n",
      "f1_micro score: 0.8130441038578586\n",
      "f1_macro score: 0.8131676935326292\n",
      "precision_micro score: 0.8130441038578585\n",
      "precision_macro score: 0.8156295211528445\n",
      "recall_micro score: 0.8130441038578585\n",
      "recall_macro score: 0.8137086447835671\n",
      "\n",
      "Random OverSampling\n",
      "f1_micro score: 0.8369924966968496\n",
      "f1_macro score: 0.8368855163907423\n",
      "precision_micro score: 0.8369924966968496\n",
      "precision_macro score: 0.837371745693148\n",
      "recall_micro score: 0.8369924966968496\n",
      "recall_macro score: 0.8369954033505437\n",
      "\n",
      "SMOTE OverSampling\n",
      "f1_micro score: 0.8148850261221622\n",
      "f1_macro score: 0.8142022450821775\n",
      "precision_micro score: 0.8148850261221622\n",
      "precision_macro score: 0.81758266449704\n",
      "recall_micro score: 0.8148850261221622\n",
      "recall_macro score: 0.8148962667654256\n",
      "\n",
      "Borderline SMOTE OverSampling\n",
      "f1_micro score: 0.809279125301526\n",
      "f1_macro score: 0.8095146445106772\n",
      "precision_micro score: 0.809279125301526\n",
      "precision_macro score: 0.8137795158854024\n",
      "recall_micro score: 0.809279125301526\n",
      "recall_macro score: 0.8092902424678126\n",
      "\n",
      "SVM SMOTE OverSampling\n",
      "f1_micro score: 0.7781948663548548\n",
      "f1_macro score: 0.8054757961450104\n",
      "precision_micro score: 0.7781948663548548\n",
      "precision_macro score: 0.8105024007751641\n",
      "recall_micro score: 0.7781948663548548\n",
      "recall_macro score: 0.8029392515373823\n",
      "\n",
      "Random Undersampling\n",
      "f1_micro score: 0.9114921199796644\n",
      "f1_macro score: 0.3178988019924049\n",
      "precision_micro score: 0.9114921199796644\n",
      "precision_macro score: 0.30383070665988815\n",
      "recall_micro score: 0.9114921199796644\n",
      "recall_macro score: 0.3333333333333333\n",
      "\n",
      "Near Miss 1 Undersampling\n",
      "f1_micro score: 0.3711237553342816\n",
      "f1_macro score: 0.3677988710162623\n",
      "precision_micro score: 0.3711237553342817\n",
      "precision_macro score: 0.37141136641136635\n",
      "recall_micro score: 0.3711237553342817\n",
      "recall_macro score: 0.37094017094017095\n",
      "\n",
      "Near Miss 2 Undersampling\n",
      "f1_micro score: 0.5917496443812233\n",
      "f1_macro score: 0.5927640254594277\n",
      "precision_micro score: 0.5917496443812233\n",
      "precision_macro score: 0.6120207034680719\n",
      "recall_micro score: 0.5917496443812233\n",
      "recall_macro score: 0.591025641025641\n",
      "\n",
      "Near Miss 3 Undersampling\n",
      "f1_micro score: 0.3386913229018492\n",
      "f1_macro score: 0.3345219927856674\n",
      "precision_micro score: 0.3386913229018493\n",
      "precision_macro score: 0.3374857598541809\n",
      "recall_micro score: 0.3386913229018493\n",
      "recall_macro score: 0.3405982905982906\n",
      "\n",
      "Tomek Links Undersampling\n",
      "f1_micro score: 0.6450909090909092\n",
      "f1_macro score: 0.3719423807352113\n",
      "precision_micro score: 0.6450909090909092\n",
      "precision_macro score: 0.38956777187178976\n",
      "recall_micro score: 0.6450909090909092\n",
      "recall_macro score: 0.3790638406225312\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8148850261221622\n",
      "f1_macro score: 0.8142022450821775\n",
      "precision_micro score: 0.8148850261221622\n",
      "precision_macro score: 0.81758266449704\n",
      "recall_micro score: 0.8148850261221622\n",
      "recall_macro score: 0.8148962667654256\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(xgb, X_smote, y_smote, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_typ...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;objective&#x27;: [&#x27;multiclass:softmax&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_typ...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;objective&#x27;: [&#x27;multiclass:softmax&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_typ...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'objective': ['multiclass:softmax']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'objective':['multiclass:softmax'],\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator= xgb, param_grid=param_grid, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik untuk Decision Tree Classifier\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'objective': 'multiclass:softmax'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter terbaik untuk Decision Tree Classifier\")\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = XGBClassifier(**xgb_grid.best_params_)\n",
    "best_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.8083851466932088\n",
      "f1_macro score: 0.8076922797657542\n",
      "precision_micro score: 0.8083851466932088\n",
      "precision_macro score: 0.809893549067076\n",
      "recall_micro score: 0.8083851466932088\n",
      "recall_macro score: 0.8087637531137226\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['f1_micro', 'f1_macro', 'precision_micro', 'precision_macro', 'recall_micro', 'recall_macro']\n",
    "for i in range(len(scoring)):\n",
    "    score = cross_val_score(best_xgb, X_train, y_train, scoring=scoring[i], cv=cv, n_jobs=-1)\n",
    "    print(f\"{scoring[i]} score: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8075965130759651\n",
      "F1 Score: 0.8074524851291326\n",
      "Recall Score: 0.8075233139651775\n",
      "Precision Score: 0.8074394862592809\n"
     ]
    }
   ],
   "source": [
    "prediction = best_xgb.predict(X_test)\n",
    "classification_metrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>id</th>\n",
       "      <th>B_avg_KD</th>\n",
       "      <th>B_avg_opp_KD</th>\n",
       "      <th>B_avg_SIG_STR_pct</th>\n",
       "      <th>B_avg_opp_SIG_STR_pct</th>\n",
       "      <th>B_avg_TD_pct</th>\n",
       "      <th>B_avg_opp_TD_pct</th>\n",
       "      <th>B_avg_SUB_ATT</th>\n",
       "      <th>B_avg_opp_SUB_ATT</th>\n",
       "      <th>B_avg_REV</th>\n",
       "      <th>B_avg_opp_REV</th>\n",
       "      <th>B_avg_SIG_STR_att</th>\n",
       "      <th>B_avg_SIG_STR_landed</th>\n",
       "      <th>B_avg_opp_SIG_STR_att</th>\n",
       "      <th>B_avg_opp_SIG_STR_landed</th>\n",
       "      <th>B_avg_TOTAL_STR_att</th>\n",
       "      <th>B_avg_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_att</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_TD_att</th>\n",
       "      <th>B_avg_TD_landed</th>\n",
       "      <th>B_avg_opp_TD_att</th>\n",
       "      <th>B_avg_opp_TD_landed</th>\n",
       "      <th>B_avg_HEAD_att</th>\n",
       "      <th>B_avg_HEAD_landed</th>\n",
       "      <th>B_avg_opp_HEAD_att</th>\n",
       "      <th>B_avg_opp_HEAD_landed</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_opp_BODY_att</th>\n",
       "      <th>B_avg_opp_BODY_landed</th>\n",
       "      <th>B_avg_LEG_att</th>\n",
       "      <th>B_avg_LEG_landed</th>\n",
       "      <th>B_avg_opp_LEG_att</th>\n",
       "      <th>B_avg_opp_LEG_landed</th>\n",
       "      <th>B_avg_DISTANCE_att</th>\n",
       "      <th>B_avg_DISTANCE_landed</th>\n",
       "      <th>B_avg_opp_DISTANCE_att</th>\n",
       "      <th>B_avg_opp_DISTANCE_landed</th>\n",
       "      <th>...</th>\n",
       "      <th>R_avg_opp_DISTANCE_landed</th>\n",
       "      <th>R_avg_CLINCH_att</th>\n",
       "      <th>R_avg_CLINCH_landed</th>\n",
       "      <th>R_avg_opp_CLINCH_att</th>\n",
       "      <th>R_avg_opp_CLINCH_landed</th>\n",
       "      <th>R_avg_GROUND_att</th>\n",
       "      <th>R_avg_GROUND_landed</th>\n",
       "      <th>R_avg_opp_GROUND_att</th>\n",
       "      <th>R_avg_opp_GROUND_landed</th>\n",
       "      <th>R_avg_CTRL_time(seconds)</th>\n",
       "      <th>R_avg_opp_CTRL_time(seconds)</th>\n",
       "      <th>R_total_time_fought(seconds)</th>\n",
       "      <th>R_total_rounds_fought</th>\n",
       "      <th>R_total_title_bouts</th>\n",
       "      <th>R_current_win_streak</th>\n",
       "      <th>R_current_lose_streak</th>\n",
       "      <th>R_longest_win_streak</th>\n",
       "      <th>R_wins</th>\n",
       "      <th>R_losses</th>\n",
       "      <th>R_draw</th>\n",
       "      <th>R_win_by_Decision_Majority</th>\n",
       "      <th>R_win_by_Decision_Split</th>\n",
       "      <th>R_win_by_Decision_Unanimous</th>\n",
       "      <th>R_win_by_KO/TKO</th>\n",
       "      <th>R_win_by_Submission</th>\n",
       "      <th>R_win_by_TKO_Doctor_Stoppage</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>B_age</th>\n",
       "      <th>R_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.937500</td>\n",
       "      <td>42.06250</td>\n",
       "      <td>68.81250</td>\n",
       "      <td>28.437500</td>\n",
       "      <td>131.625000</td>\n",
       "      <td>80.312500</td>\n",
       "      <td>145.4375</td>\n",
       "      <td>79.640625</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>2.0625</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>60.3125</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>49.812500</td>\n",
       "      <td>13.500</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>17.12500</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>58.125000</td>\n",
       "      <td>17.68750</td>\n",
       "      <td>44.187500</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>32.625000</td>\n",
       "      <td>7.4375</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>94.937500</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.94</td>\n",
       "      <td>152.40</td>\n",
       "      <td>115.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.473125</td>\n",
       "      <td>0.371875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.312500</td>\n",
       "      <td>23.75000</td>\n",
       "      <td>53.87500</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>63.687500</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>109.8750</td>\n",
       "      <td>70.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>37.1250</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>11.375</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>7.6875</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>3.62500</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>42.687500</td>\n",
       "      <td>16.06250</td>\n",
       "      <td>47.250000</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>29.001953</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>11.433594</td>\n",
       "      <td>15.714844</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>1.930664</td>\n",
       "      <td>1.556641</td>\n",
       "      <td>7.413086</td>\n",
       "      <td>6.749023</td>\n",
       "      <td>222.675781</td>\n",
       "      <td>273.668945</td>\n",
       "      <td>895.705078</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.18</td>\n",
       "      <td>182.88</td>\n",
       "      <td>170.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>36.50000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>79.640625</td>\n",
       "      <td>5.835938</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.0000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>10.500</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>16.50000</td>\n",
       "      <td>9.50000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.18</td>\n",
       "      <td>177.80</td>\n",
       "      <td>145.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>109.0000</td>\n",
       "      <td>79.640625</td>\n",
       "      <td>5.835938</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.968750</td>\n",
       "      <td>5.4375</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>5.632812</td>\n",
       "      <td>3.786182</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.484375</td>\n",
       "      <td>3.468750</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>112.085938</td>\n",
       "      <td>85.261719</td>\n",
       "      <td>674.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.10</td>\n",
       "      <td>162.56</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.505312</td>\n",
       "      <td>0.439375</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.067187</td>\n",
       "      <td>1.002136</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>29.890625</td>\n",
       "      <td>14.53125</td>\n",
       "      <td>13.90625</td>\n",
       "      <td>5.171875</td>\n",
       "      <td>54.515625</td>\n",
       "      <td>39.078125</td>\n",
       "      <td>22.6875</td>\n",
       "      <td>13.531250</td>\n",
       "      <td>2.468750</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>24.2500</td>\n",
       "      <td>11.265625</td>\n",
       "      <td>8.453125</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2.328125</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>2.40625</td>\n",
       "      <td>2.15625</td>\n",
       "      <td>3.3125</td>\n",
       "      <td>1.828125</td>\n",
       "      <td>3.046875</td>\n",
       "      <td>2.140625</td>\n",
       "      <td>18.984375</td>\n",
       "      <td>5.71875</td>\n",
       "      <td>9.984375</td>\n",
       "      <td>2.546875</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.26</td>\n",
       "      <td>182.88</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_class   id  ...  R_Stance_Southpaw  R_Stance_Switch\n",
       "0             1  0.0  ...              False            False\n",
       "1             6  1.0  ...              False            False\n",
       "2             4  2.0  ...              False            False\n",
       "3             3  3.0  ...              False            False\n",
       "4             6  4.0  ...              False            False\n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv('dataframe/UFC_Pre_Kombinasi7.csv')\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_avg_opp_TOTAL_STR_landed', 'B_avg_REV', 'R_avg_opp_GROUND_landed', 'R_Stance_Orthodox', 'R_avg_opp_CTRL_time(seconds)', 'B_avg_TD_att', 'R_avg_opp_BODY_landed', 'R_avg_DISTANCE_att', 'R_total_rounds_fought', 'R_avg_KD', 'B_avg_opp_BODY_att', 'B_avg_opp_DISTANCE_landed', 'B_avg_HEAD_att', 'B_avg_opp_LEG_att', 'gender', 'B_avg_opp_TD_att', 'R_avg_opp_GROUND_att', 'R_current_win_streak', 'R_win_by_Decision_Majority', 'R_avg_LEG_att', 'B_avg_TOTAL_STR_landed', 'B_win_by_TKO_Doctor_Stoppage', 'R_avg_DISTANCE_landed', 'R_avg_opp_SIG_STR_pct', 'B_win_by_Decision_Split', 'B_avg_opp_TD_pct', 'R_avg_SIG_STR_pct', 'R_avg_opp_HEAD_att', 'R_Stance_Switch', 'B_avg_LEG_landed', 'R_avg_opp_SIG_STR_landed', 'B_avg_DISTANCE_landed', 'R_avg_HEAD_landed', 'R_avg_HEAD_att', 'R_longest_win_streak', 'B_avg_CLINCH_att', 'R_avg_GROUND_att', 'R_total_title_bouts', 'R_avg_opp_TOTAL_STR_landed', 'B_avg_opp_GROUND_att', 'B_avg_SIG_STR_landed', 'B_avg_opp_REV', 'B_Stance_Switch', 'B_Height_cms', 'R_avg_GROUND_landed', 'R_avg_opp_KD', 'R_avg_opp_DISTANCE_att', 'B_age', 'B_avg_opp_CLINCH_landed', 'R_draw', 'B_win_by_Submission', 'B_win_by_Decision_Majority', 'R_avg_CLINCH_landed', 'B_avg_GROUND_landed', 'B_avg_opp_CTRL_time(seconds)', 'R_win_by_Submission', 'R_avg_opp_CLINCH_att', 'R_current_lose_streak', 'R_avg_SIG_STR_landed', 'B_avg_opp_HEAD_landed', 'B_avg_TD_landed', 'R_win_by_Decision_Split', 'B_total_rounds_fought', 'B_Stance_Open Stance', 'R_Weight_lbs', 'B_avg_SIG_STR_pct', 'B_total_title_bouts', 'R_avg_CTRL_time(seconds)', 'R_avg_TOTAL_STR_att', 'R_age', 'R_avg_opp_LEG_att', 'R_avg_TOTAL_STR_landed', 'R_total_time_fought(seconds)', 'Winner', 'R_avg_opp_TD_att', 'R_avg_SIG_STR_att', 'R_avg_REV', 'B_avg_CTRL_time(seconds)', 'B_longest_win_streak', 'R_avg_TD_landed', 'R_avg_opp_HEAD_landed', 'B_win_by_KO/TKO', 'R_avg_BODY_landed', 'B_wins', 'B_avg_TOTAL_STR_att', 'B_Weight_lbs', 'B_avg_opp_GROUND_landed', 'R_avg_LEG_landed', 'B_avg_opp_TOTAL_STR_att', 'weight_class', 'R_avg_opp_CLINCH_landed', 'R_losses', 'B_avg_opp_SIG_STR_att', 'R_avg_opp_TD_landed', 'R_avg_CLINCH_att', 'B_avg_opp_BODY_landed', 'B_total_time_fought(seconds)', 'R_avg_opp_TD_pct', 'B_avg_KD', 'R_Stance_Open Stance', 'B_avg_opp_DISTANCE_att', 'R_avg_opp_TOTAL_STR_att', 'B_win_by_Decision_Unanimous', 'B_avg_opp_SIG_STR_landed', 'B_avg_opp_KD', 'R_avg_opp_SUB_ATT', 'B_avg_BODY_att', 'R_Height_cms', 'B_avg_opp_SUB_ATT', 'B_avg_opp_TD_landed', 'R_win_by_Decision_Unanimous', 'R_avg_BODY_att', 'B_current_lose_streak', 'B_Stance_Southpaw', 'R_avg_opp_LEG_landed', 'B_avg_TD_pct', 'B_avg_SUB_ATT', 'B_avg_CLINCH_landed', 'R_avg_opp_BODY_att', 'R_avg_SUB_ATT', 'R_avg_opp_REV', 'R_Reach_cms', 'B_avg_DISTANCE_att', 'B_avg_opp_CLINCH_att', 'B_avg_LEG_att', 'B_avg_GROUND_att', 'B_losses', 'B_avg_HEAD_landed', 'R_win_by_TKO_Doctor_Stoppage', 'B_avg_opp_SIG_STR_pct', 'R_avg_opp_DISTANCE_landed', 'B_avg_SIG_STR_att', 'R_avg_TD_pct', 'B_avg_opp_LEG_landed', 'R_Stance_Southpaw', 'B_avg_BODY_landed', 'R_avg_TD_att', 'R_wins', 'B_avg_opp_HEAD_att', 'B_current_win_streak', 'B_Stance_Orthodox', 'B_draw', 'R_win_by_KO/TKO', 'R_avg_opp_SIG_STR_att'}\n",
      "{'B_avg_opp_TOTAL_STR_landed', 'B_avg_REV', 'R_avg_opp_GROUND_landed', 'R_Stance_Orthodox', 'R_avg_opp_CTRL_time(seconds)', 'B_avg_TD_att', 'R_avg_opp_BODY_landed', 'R_avg_DISTANCE_att', 'R_total_rounds_fought', 'R_avg_KD', 'B_avg_opp_BODY_att', 'B_avg_opp_DISTANCE_landed', 'B_avg_HEAD_att', 'B_avg_opp_LEG_att', 'gender', 'B_avg_opp_TD_att', 'R_avg_opp_GROUND_att', 'R_current_win_streak', 'id', 'R_win_by_Decision_Majority', 'R_avg_LEG_att', 'B_avg_TOTAL_STR_landed', 'B_win_by_TKO_Doctor_Stoppage', 'R_avg_DISTANCE_landed', 'R_avg_opp_SIG_STR_pct', 'B_win_by_Decision_Split', 'B_avg_opp_TD_pct', 'R_avg_SIG_STR_pct', 'R_avg_opp_HEAD_att', 'R_Stance_Switch', 'B_avg_LEG_landed', 'R_avg_opp_SIG_STR_landed', 'B_avg_DISTANCE_landed', 'R_avg_HEAD_landed', 'R_avg_HEAD_att', 'R_longest_win_streak', 'B_avg_CLINCH_att', 'R_avg_GROUND_att', 'R_total_title_bouts', 'R_avg_opp_TOTAL_STR_landed', 'B_avg_opp_GROUND_att', 'B_avg_SIG_STR_landed', 'B_avg_opp_REV', 'B_Stance_Switch', 'B_Height_cms', 'R_avg_GROUND_landed', 'R_avg_opp_KD', 'R_avg_opp_DISTANCE_att', 'B_age', 'B_avg_opp_CLINCH_landed', 'R_draw', 'B_win_by_Submission', 'B_win_by_Decision_Majority', 'R_avg_CLINCH_landed', 'B_avg_GROUND_landed', 'B_avg_opp_CTRL_time(seconds)', 'R_win_by_Submission', 'R_avg_opp_CLINCH_att', 'R_current_lose_streak', 'R_avg_SIG_STR_landed', 'B_avg_opp_HEAD_landed', 'B_avg_TD_landed', 'R_win_by_Decision_Split', 'B_total_rounds_fought', 'B_Stance_Open Stance', 'R_Weight_lbs', 'B_avg_SIG_STR_pct', 'B_total_title_bouts', 'R_avg_CTRL_time(seconds)', 'R_avg_TOTAL_STR_att', 'R_age', 'R_avg_opp_LEG_att', 'R_avg_TOTAL_STR_landed', 'R_total_time_fought(seconds)', 'R_avg_opp_TD_att', 'R_avg_SIG_STR_att', 'R_avg_REV', 'B_avg_CTRL_time(seconds)', 'B_longest_win_streak', 'R_avg_TD_landed', 'R_avg_opp_HEAD_landed', 'B_win_by_KO/TKO', 'R_avg_BODY_landed', 'B_wins', 'B_avg_TOTAL_STR_att', 'B_Weight_lbs', 'B_avg_opp_GROUND_landed', 'R_avg_LEG_landed', 'B_avg_opp_TOTAL_STR_att', 'weight_class', 'R_avg_opp_CLINCH_landed', 'R_losses', 'B_avg_opp_SIG_STR_att', 'R_avg_opp_TD_landed', 'R_avg_CLINCH_att', 'B_avg_opp_BODY_landed', 'B_total_time_fought(seconds)', 'R_avg_opp_TD_pct', 'B_avg_KD', 'R_Stance_Open Stance', 'B_avg_opp_DISTANCE_att', 'R_avg_opp_TOTAL_STR_att', 'B_win_by_Decision_Unanimous', 'B_avg_opp_SIG_STR_landed', 'B_avg_opp_KD', 'R_avg_opp_SUB_ATT', 'B_avg_BODY_att', 'R_Height_cms', 'B_avg_opp_SUB_ATT', 'B_avg_opp_TD_landed', 'R_win_by_Decision_Unanimous', 'R_avg_BODY_att', 'B_current_lose_streak', 'B_Stance_Southpaw', 'R_avg_opp_LEG_landed', 'B_avg_TD_pct', 'B_avg_SUB_ATT', 'B_avg_CLINCH_landed', 'R_avg_opp_BODY_att', 'R_avg_SUB_ATT', 'R_avg_opp_REV', 'R_Reach_cms', 'B_avg_DISTANCE_att', 'B_avg_opp_CLINCH_att', 'B_avg_LEG_att', 'B_avg_GROUND_att', 'B_losses', 'B_avg_HEAD_landed', 'R_win_by_TKO_Doctor_Stoppage', 'B_avg_opp_SIG_STR_pct', 'R_avg_opp_DISTANCE_landed', 'B_avg_SIG_STR_att', 'R_avg_TD_pct', 'B_avg_opp_LEG_landed', 'R_Stance_Southpaw', 'B_avg_BODY_landed', 'R_avg_TD_att', 'R_wins', 'B_avg_opp_HEAD_att', 'B_current_win_streak', 'B_Stance_Orthodox', 'B_draw', 'R_win_by_KO/TKO', 'R_avg_opp_SIG_STR_att'}\n",
      "{'Winner'}\n",
      "{'id'}\n"
     ]
    }
   ],
   "source": [
    "print(set(df.columns))\n",
    "print(set(df_kaggle.columns))\n",
    "\n",
    "print(set(df.columns) - set(df_kaggle.columns))\n",
    "print(set(df_kaggle.columns) - set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = df_kaggle.drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>B_avg_KD</th>\n",
       "      <th>B_avg_opp_KD</th>\n",
       "      <th>B_avg_SIG_STR_pct</th>\n",
       "      <th>B_avg_opp_SIG_STR_pct</th>\n",
       "      <th>B_avg_TD_pct</th>\n",
       "      <th>B_avg_opp_TD_pct</th>\n",
       "      <th>B_avg_SUB_ATT</th>\n",
       "      <th>B_avg_opp_SUB_ATT</th>\n",
       "      <th>B_avg_REV</th>\n",
       "      <th>B_avg_opp_REV</th>\n",
       "      <th>B_avg_SIG_STR_att</th>\n",
       "      <th>B_avg_SIG_STR_landed</th>\n",
       "      <th>B_avg_opp_SIG_STR_att</th>\n",
       "      <th>B_avg_opp_SIG_STR_landed</th>\n",
       "      <th>B_avg_TOTAL_STR_att</th>\n",
       "      <th>B_avg_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_att</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_TD_att</th>\n",
       "      <th>B_avg_TD_landed</th>\n",
       "      <th>B_avg_opp_TD_att</th>\n",
       "      <th>B_avg_opp_TD_landed</th>\n",
       "      <th>B_avg_HEAD_att</th>\n",
       "      <th>B_avg_HEAD_landed</th>\n",
       "      <th>B_avg_opp_HEAD_att</th>\n",
       "      <th>B_avg_opp_HEAD_landed</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_opp_BODY_att</th>\n",
       "      <th>B_avg_opp_BODY_landed</th>\n",
       "      <th>B_avg_LEG_att</th>\n",
       "      <th>B_avg_LEG_landed</th>\n",
       "      <th>B_avg_opp_LEG_att</th>\n",
       "      <th>B_avg_opp_LEG_landed</th>\n",
       "      <th>B_avg_DISTANCE_att</th>\n",
       "      <th>B_avg_DISTANCE_landed</th>\n",
       "      <th>B_avg_opp_DISTANCE_att</th>\n",
       "      <th>B_avg_opp_DISTANCE_landed</th>\n",
       "      <th>B_avg_CLINCH_att</th>\n",
       "      <th>...</th>\n",
       "      <th>R_avg_opp_DISTANCE_landed</th>\n",
       "      <th>R_avg_CLINCH_att</th>\n",
       "      <th>R_avg_CLINCH_landed</th>\n",
       "      <th>R_avg_opp_CLINCH_att</th>\n",
       "      <th>R_avg_opp_CLINCH_landed</th>\n",
       "      <th>R_avg_GROUND_att</th>\n",
       "      <th>R_avg_GROUND_landed</th>\n",
       "      <th>R_avg_opp_GROUND_att</th>\n",
       "      <th>R_avg_opp_GROUND_landed</th>\n",
       "      <th>R_avg_CTRL_time(seconds)</th>\n",
       "      <th>R_avg_opp_CTRL_time(seconds)</th>\n",
       "      <th>R_total_time_fought(seconds)</th>\n",
       "      <th>R_total_rounds_fought</th>\n",
       "      <th>R_total_title_bouts</th>\n",
       "      <th>R_current_win_streak</th>\n",
       "      <th>R_current_lose_streak</th>\n",
       "      <th>R_longest_win_streak</th>\n",
       "      <th>R_wins</th>\n",
       "      <th>R_losses</th>\n",
       "      <th>R_draw</th>\n",
       "      <th>R_win_by_Decision_Majority</th>\n",
       "      <th>R_win_by_Decision_Split</th>\n",
       "      <th>R_win_by_Decision_Unanimous</th>\n",
       "      <th>R_win_by_KO/TKO</th>\n",
       "      <th>R_win_by_Submission</th>\n",
       "      <th>R_win_by_TKO_Doctor_Stoppage</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>B_age</th>\n",
       "      <th>R_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.937500</td>\n",
       "      <td>42.062500</td>\n",
       "      <td>68.812500</td>\n",
       "      <td>28.437500</td>\n",
       "      <td>131.625000</td>\n",
       "      <td>80.312500</td>\n",
       "      <td>145.437500</td>\n",
       "      <td>79.640625</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>60.312500</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>49.812500</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.12500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>58.125000</td>\n",
       "      <td>17.68750</td>\n",
       "      <td>44.187500</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.625000</td>\n",
       "      <td>7.437500</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>94.937500</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.94</td>\n",
       "      <td>152.40</td>\n",
       "      <td>115.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.473125</td>\n",
       "      <td>0.371875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.312500</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>53.875000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>63.687500</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>109.875000</td>\n",
       "      <td>70.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>7.687500</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>42.687500</td>\n",
       "      <td>16.06250</td>\n",
       "      <td>47.250000</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.001953</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.433594</td>\n",
       "      <td>15.714844</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>1.930664</td>\n",
       "      <td>1.556641</td>\n",
       "      <td>7.413086</td>\n",
       "      <td>6.749023</td>\n",
       "      <td>222.675781</td>\n",
       "      <td>273.668945</td>\n",
       "      <td>895.705078</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.18</td>\n",
       "      <td>182.88</td>\n",
       "      <td>170.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>79.640625</td>\n",
       "      <td>5.835938</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>16.50000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.18</td>\n",
       "      <td>177.80</td>\n",
       "      <td>145.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>79.640625</td>\n",
       "      <td>5.835938</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.968750</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>5.632812</td>\n",
       "      <td>3.786182</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.484375</td>\n",
       "      <td>3.468750</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>112.085938</td>\n",
       "      <td>85.261719</td>\n",
       "      <td>674.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.10</td>\n",
       "      <td>162.56</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.505312</td>\n",
       "      <td>0.439375</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.067187</td>\n",
       "      <td>1.002136</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>29.890625</td>\n",
       "      <td>14.531250</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>5.171875</td>\n",
       "      <td>54.515625</td>\n",
       "      <td>39.078125</td>\n",
       "      <td>22.687500</td>\n",
       "      <td>13.531250</td>\n",
       "      <td>2.468750</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>11.265625</td>\n",
       "      <td>8.453125</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.328125</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>2.40625</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.828125</td>\n",
       "      <td>3.046875</td>\n",
       "      <td>2.140625</td>\n",
       "      <td>18.984375</td>\n",
       "      <td>5.71875</td>\n",
       "      <td>9.984375</td>\n",
       "      <td>2.546875</td>\n",
       "      <td>3.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.26</td>\n",
       "      <td>182.88</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>3</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.461132</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.217562</td>\n",
       "      <td>0.192031</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.068893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.547211</td>\n",
       "      <td>30.941406</td>\n",
       "      <td>66.855469</td>\n",
       "      <td>27.823242</td>\n",
       "      <td>90.187500</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>88.656250</td>\n",
       "      <td>43.437500</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>0.733398</td>\n",
       "      <td>2.093750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>51.546875</td>\n",
       "      <td>18.554688</td>\n",
       "      <td>51.519531</td>\n",
       "      <td>15.902344</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>5.257812</td>\n",
       "      <td>4.593750</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>4.429688</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>52.110474</td>\n",
       "      <td>18.06250</td>\n",
       "      <td>50.195312</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.968750</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>5.632812</td>\n",
       "      <td>3.786182</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.484375</td>\n",
       "      <td>3.468750</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>112.085938</td>\n",
       "      <td>85.261719</td>\n",
       "      <td>674.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.64</td>\n",
       "      <td>175.26</td>\n",
       "      <td>135.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968750</td>\n",
       "      <td>4.093750</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>12.375000</td>\n",
       "      <td>8.406250</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>87.843750</td>\n",
       "      <td>143.281250</td>\n",
       "      <td>475.312500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.34</td>\n",
       "      <td>185.42</td>\n",
       "      <td>170.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>5</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.360254</td>\n",
       "      <td>0.501284</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.119775</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.378906</td>\n",
       "      <td>39.505371</td>\n",
       "      <td>90.445801</td>\n",
       "      <td>47.699219</td>\n",
       "      <td>104.798828</td>\n",
       "      <td>41.519043</td>\n",
       "      <td>92.248047</td>\n",
       "      <td>49.399902</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.027344</td>\n",
       "      <td>0.570801</td>\n",
       "      <td>87.966797</td>\n",
       "      <td>28.396973</td>\n",
       "      <td>66.450684</td>\n",
       "      <td>28.889160</td>\n",
       "      <td>11.666504</td>\n",
       "      <td>8.790527</td>\n",
       "      <td>17.12500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.745605</td>\n",
       "      <td>2.317871</td>\n",
       "      <td>3.665527</td>\n",
       "      <td>3.273926</td>\n",
       "      <td>90.642090</td>\n",
       "      <td>30.81543</td>\n",
       "      <td>77.714355</td>\n",
       "      <td>38.344238</td>\n",
       "      <td>7.118164</td>\n",
       "      <td>...</td>\n",
       "      <td>6.437500</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>16.437500</td>\n",
       "      <td>12.062500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>455.937500</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.18</td>\n",
       "      <td>180.34</td>\n",
       "      <td>155.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.75000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.597656</td>\n",
       "      <td>1.789062</td>\n",
       "      <td>1.273438</td>\n",
       "      <td>15.714844</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>2.105469</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>52.361328</td>\n",
       "      <td>126.683594</td>\n",
       "      <td>319.214844</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.34</td>\n",
       "      <td>187.96</td>\n",
       "      <td>205.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>53.164062</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.12500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.818848</td>\n",
       "      <td>10.252441</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.730957</td>\n",
       "      <td>1.084473</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>2.122070</td>\n",
       "      <td>1.442871</td>\n",
       "      <td>15.434570</td>\n",
       "      <td>9.313477</td>\n",
       "      <td>8.772461</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>145.980469</td>\n",
       "      <td>107.133301</td>\n",
       "      <td>414.783203</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.26</td>\n",
       "      <td>172.72</td>\n",
       "      <td>135.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight_class  B_avg_KD  ...  R_Stance_Southpaw  R_Stance_Switch\n",
       "0               1  0.000000  ...              False            False\n",
       "1               6  0.000000  ...              False            False\n",
       "2               4  0.000000  ...              False            False\n",
       "3               3  0.000000  ...              False            False\n",
       "4               6  0.000000  ...              False            False\n",
       "..            ...       ...  ...                ...              ...\n",
       "597             3  0.015625  ...              False            False\n",
       "598             5  0.000000  ...              False            False\n",
       "599             5  0.750000  ...              False            False\n",
       "600             9  0.000000  ...              False            False\n",
       "601             3  0.000000  ...              False            False\n",
       "\n",
       "[602 rows x 143 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2,\n",
       "       2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0,\n",
       "       0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2,\n",
       "       0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
       "       0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2,\n",
       "       2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2,\n",
       "       2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0,\n",
       "       0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_kaggle = best_hypeparam_rfc.predict(df_kaggle)\n",
    "prediction_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {0:'Blue', 1:'Draw', 2:'Red'}\n",
    "def map_class(value):\n",
    "    return class_mapping.get(value, value)\n",
    "\n",
    "vectorized_mapping  = np.vectorize(map_class)\n",
    "\n",
    "prediction_kaggle = vectorized_mapping(prediction_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blue', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Blue', 'Blue', 'Blue', 'Blue', 'Red',\n",
       "       'Blue', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Blue', 'Blue', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Blue',\n",
       "       'Blue', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Blue',\n",
       "       'Blue', 'Red', 'Red', 'Blue', 'Blue', 'Blue', 'Blue', 'Blue',\n",
       "       'Red', 'Blue', 'Blue', 'Red', 'Blue', 'Blue', 'Blue', 'Red',\n",
       "       'Blue', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue',\n",
       "       'Blue', 'Blue', 'Red', 'Blue', 'Blue', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Blue', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Blue', 'Red', 'Blue', 'Blue', 'Blue',\n",
       "       'Blue', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Blue', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Blue', 'Blue', 'Blue', 'Red', 'Blue',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Red', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Blue', 'Red', 'Blue', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Blue', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Blue', 'Blue', 'Blue', 'Red', 'Blue',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Blue',\n",
       "       'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue',\n",
       "       'Blue', 'Blue', 'Red', 'Red', 'Blue', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue',\n",
       "       'Red', 'Blue', 'Red', 'Blue', 'Red', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Blue', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Blue', 'Red', 'Blue', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Red', 'Red', 'Blue', 'Red', 'Blue', 'Red',\n",
       "       'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Blue',\n",
       "       'Blue', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Blue', 'Red',\n",
       "       'Red', 'Blue', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Blue',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red', 'Blue', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Blue', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Blue', 'Blue', 'Red', 'Blue', 'Red', 'Red', 'Red',\n",
       "       'Red', 'Red', 'Red', 'Red'], dtype='<U4')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>R_fighter</th>\n",
       "      <th>B_fighter</th>\n",
       "      <th>Referee</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>weight_class</th>\n",
       "      <th>B_avg_KD</th>\n",
       "      <th>B_avg_opp_KD</th>\n",
       "      <th>B_avg_SIG_STR_pct</th>\n",
       "      <th>B_avg_opp_SIG_STR_pct</th>\n",
       "      <th>B_avg_TD_pct</th>\n",
       "      <th>B_avg_opp_TD_pct</th>\n",
       "      <th>B_avg_SUB_ATT</th>\n",
       "      <th>B_avg_opp_SUB_ATT</th>\n",
       "      <th>B_avg_REV</th>\n",
       "      <th>B_avg_opp_REV</th>\n",
       "      <th>B_avg_SIG_STR_att</th>\n",
       "      <th>B_avg_SIG_STR_landed</th>\n",
       "      <th>B_avg_opp_SIG_STR_att</th>\n",
       "      <th>B_avg_opp_SIG_STR_landed</th>\n",
       "      <th>B_avg_TOTAL_STR_att</th>\n",
       "      <th>B_avg_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_att</th>\n",
       "      <th>B_avg_opp_TOTAL_STR_landed</th>\n",
       "      <th>B_avg_TD_att</th>\n",
       "      <th>B_avg_TD_landed</th>\n",
       "      <th>B_avg_opp_TD_att</th>\n",
       "      <th>B_avg_opp_TD_landed</th>\n",
       "      <th>B_avg_HEAD_att</th>\n",
       "      <th>B_avg_HEAD_landed</th>\n",
       "      <th>B_avg_opp_HEAD_att</th>\n",
       "      <th>B_avg_opp_HEAD_landed</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_opp_BODY_att</th>\n",
       "      <th>B_avg_opp_BODY_landed</th>\n",
       "      <th>B_avg_LEG_att</th>\n",
       "      <th>B_avg_LEG_landed</th>\n",
       "      <th>...</th>\n",
       "      <th>R_avg_opp_BODY_landed</th>\n",
       "      <th>R_avg_LEG_att</th>\n",
       "      <th>R_avg_LEG_landed</th>\n",
       "      <th>R_avg_opp_LEG_att</th>\n",
       "      <th>R_avg_opp_LEG_landed</th>\n",
       "      <th>R_avg_DISTANCE_att</th>\n",
       "      <th>R_avg_DISTANCE_landed</th>\n",
       "      <th>R_avg_opp_DISTANCE_att</th>\n",
       "      <th>R_avg_opp_DISTANCE_landed</th>\n",
       "      <th>R_avg_CLINCH_att</th>\n",
       "      <th>R_avg_CLINCH_landed</th>\n",
       "      <th>R_avg_opp_CLINCH_att</th>\n",
       "      <th>R_avg_opp_CLINCH_landed</th>\n",
       "      <th>R_avg_GROUND_att</th>\n",
       "      <th>R_avg_GROUND_landed</th>\n",
       "      <th>R_avg_opp_GROUND_att</th>\n",
       "      <th>R_avg_opp_GROUND_landed</th>\n",
       "      <th>R_avg_CTRL_time(seconds)</th>\n",
       "      <th>R_avg_opp_CTRL_time(seconds)</th>\n",
       "      <th>R_total_time_fought(seconds)</th>\n",
       "      <th>R_total_rounds_fought</th>\n",
       "      <th>R_total_title_bouts</th>\n",
       "      <th>R_current_win_streak</th>\n",
       "      <th>R_current_lose_streak</th>\n",
       "      <th>R_longest_win_streak</th>\n",
       "      <th>R_wins</th>\n",
       "      <th>R_losses</th>\n",
       "      <th>R_draw</th>\n",
       "      <th>R_win_by_Decision_Majority</th>\n",
       "      <th>R_win_by_Decision_Split</th>\n",
       "      <th>R_win_by_Decision_Unanimous</th>\n",
       "      <th>R_win_by_KO/TKO</th>\n",
       "      <th>R_win_by_Submission</th>\n",
       "      <th>R_win_by_TKO_Doctor_Stoppage</th>\n",
       "      <th>R_Stance</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>B_age</th>\n",
       "      <th>R_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tecia Torres</td>\n",
       "      <td>Juliana Lima</td>\n",
       "      <td>Chris Tognoni</td>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>WomenStrawweight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.937500</td>\n",
       "      <td>42.06250</td>\n",
       "      <td>68.81250</td>\n",
       "      <td>28.437500</td>\n",
       "      <td>131.625000</td>\n",
       "      <td>80.312500</td>\n",
       "      <td>145.4375</td>\n",
       "      <td>98.75000</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>2.0625</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>60.3125</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>49.812500</td>\n",
       "      <td>13.500</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>18.37500</td>\n",
       "      <td>14.62500</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>13.187500</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>4.93750</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>147.812500</td>\n",
       "      <td>66.06250</td>\n",
       "      <td>130.812500</td>\n",
       "      <td>32.625000</td>\n",
       "      <td>7.437500</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>2.87500</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>94.937500</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>154.94</td>\n",
       "      <td>152.40</td>\n",
       "      <td>115.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>John Howard</td>\n",
       "      <td>Lorenz Larkin</td>\n",
       "      <td>Herb Dean</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>Boston, Massachusetts, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.473125</td>\n",
       "      <td>0.371875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.312500</td>\n",
       "      <td>23.75000</td>\n",
       "      <td>53.87500</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>63.687500</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>109.8750</td>\n",
       "      <td>70.37500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.8125</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>37.1250</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>11.375</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>7.6875</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>3.62500</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.579102</td>\n",
       "      <td>13.258789</td>\n",
       "      <td>12.456055</td>\n",
       "      <td>18.15625</td>\n",
       "      <td>14.165039</td>\n",
       "      <td>39.666992</td>\n",
       "      <td>23.71875</td>\n",
       "      <td>67.904297</td>\n",
       "      <td>29.001953</td>\n",
       "      <td>23.037109</td>\n",
       "      <td>13.837891</td>\n",
       "      <td>21.053711</td>\n",
       "      <td>15.53418</td>\n",
       "      <td>1.930664</td>\n",
       "      <td>1.556641</td>\n",
       "      <td>7.413086</td>\n",
       "      <td>6.749023</td>\n",
       "      <td>222.675781</td>\n",
       "      <td>273.668945</td>\n",
       "      <td>895.705078</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>170.18</td>\n",
       "      <td>182.88</td>\n",
       "      <td>170.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kyle Bochniak</td>\n",
       "      <td>Jeremy Kennedy</td>\n",
       "      <td>Todd Ronald Anderson</td>\n",
       "      <td>2017-07-22</td>\n",
       "      <td>Uniondale, New York, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>36.50000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>89.00000</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>6.50000</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.0000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>10.500</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>16.50000</td>\n",
       "      <td>9.50000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>170.18</td>\n",
       "      <td>177.80</td>\n",
       "      <td>145.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yao Zhikui</td>\n",
       "      <td>Royston Wee</td>\n",
       "      <td>Steve Perceval</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>Macau, China</td>\n",
       "      <td>False</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>109.0000</td>\n",
       "      <td>89.00000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>165.10</td>\n",
       "      <td>162.56</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Carlos Newton</td>\n",
       "      <td>Pat Miletich</td>\n",
       "      <td>John McCarthy</td>\n",
       "      <td>2001-05-04</td>\n",
       "      <td>Atlantic City, New Jersey, USA</td>\n",
       "      <td>True</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.505312</td>\n",
       "      <td>0.439375</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>0.067187</td>\n",
       "      <td>1.28125</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>29.890625</td>\n",
       "      <td>14.53125</td>\n",
       "      <td>13.90625</td>\n",
       "      <td>5.171875</td>\n",
       "      <td>54.515625</td>\n",
       "      <td>39.078125</td>\n",
       "      <td>22.6875</td>\n",
       "      <td>13.53125</td>\n",
       "      <td>2.46875</td>\n",
       "      <td>2.21875</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>24.2500</td>\n",
       "      <td>11.265625</td>\n",
       "      <td>8.453125</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2.328125</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>2.40625</td>\n",
       "      <td>2.15625</td>\n",
       "      <td>3.3125</td>\n",
       "      <td>1.828125</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.50000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>175.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      R_fighter       B_fighter  ... R_Weight_lbs B_age R_age\n",
       "0   0   Tecia Torres    Juliana Lima  ...        115.0  35.0  27.0\n",
       "1   1    John Howard   Lorenz Larkin  ...        170.0  28.0  31.0\n",
       "2   2  Kyle Bochniak  Jeremy Kennedy  ...        145.0  24.0  30.0\n",
       "3   3     Yao Zhikui     Royston Wee  ...        125.0  27.0  23.0\n",
       "4   4  Carlos Newton    Pat Miletich  ...        170.0  33.0  24.0\n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv('dataframe/UFC_Test_Classif_X.csv')\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = df_kaggle[['id']]\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle['Winner'] = pd.DataFrame({'Winner': prediction_kaggle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Winner\n",
       "0   0   Blue\n",
       "1   1   Blue\n",
       "2   2   Blue\n",
       "3   3    Red\n",
       "4   4    Red"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle.to_csv('dataframe/Kaggle_prediction7smote.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
